  Good afternoon everyone. My name is John Hess. Today I'm going to be joined by  Matthew Lucas, and we are going  to be talking to all of you  about practical approaches to  great app performance. Now, I'm an engineer on the  Xcode team, and I've had the  luxury of spending the last  several years focused on  performance work. First, with Project Find, and  Open Quickly, two areas of Xcode  that treat performance as the  primary feature. Most recently, I've had the  opportunity to do a survey of  Xcode GY responsiveness, and I  want to share with you the  approaches that I take to  performance work, both in code  that I'm intimately familiar  with, and in code that I'm just  experiencing for the first time. Now, if I could get everyone in  today's presentation to just  take one lesson away, it is that  all of your performance work  should be based on measurement. Before you start solving a  performance problem, you should  measure, to establish a baseline  so you know where you stand.

大家下午好。我叫John Hess。今天我要和Matthew Lucas一起讨论，我们将和你们大家讨论如何实现出色的应用程序性能。现在，我是Xcode团队的工程师，在过去的几年里，我有幸专注于性能工作。首先，通过项目查找和快速打开，将性能作为主要特征的两个XCODE区域。最近，我有机会对Xcode GY的响应性做了一个调查，我想和大家分享一下我在性能工作中采用的方法，包括我熟悉的代码以及我第一次体验的代码。现在，如果我能让大家参加今天的演讲，从中得到一个教训，那就是你们所有的表现工作都应该建立在衡量的基础上。在你开始解决一个性能问题之前，你应该测量，建立一个基线，这样你就知道你的立场。

 As you iterate on solving a  performance problem, you should  measure it each step of the way  to ensure that your performance  changes are having the impact  that you expect. When you're done solving a  performance problem, you should  measure again, so that you can  compare to your original  baseline, and make a quantified  claim about just how much you've  improved the performance of your  application. You want to share this with your  boss, your colleagues, and your  users. Now, when you think about  improving performance for your  users, you need to think about  what I like to call the total  performance impact. If you improve the functionality  and performance of one area of  your application, by 50%, but  it's something that just 1% of  your users encounter, that does  not have nearly the breadth of  impact as improving some other  feature by just 10% that all of  your users use all the time. So make sure you're not  optimizing edge cases, and make  sure that your changes are  impacting all of your users. Now how do we fix performance  bugs?  Well, how do we fix regular  bugs?  Normally it starts with some  sort of defect report from  users, and we take this report  of the application not behaving  the way that people expect, and  we find some way to synthesize  steps to reproduce so that we  can cause the failure at will. Once we've done this, we attach  a debugger to our program, so  that we can see just what our  program is doing while it is  misbehaving. We combine that with our  knowledge of how the code is  supposed to work, to modify it  as necessary and eliminate the  undesired behavior. We verify that we haven't  introduced any unwanted side  effects, and we repeat as  necessary until we've completely  solved the bug. I've fixed performance bugs in  just the same way. Except instead of using a  debugger, I use a profiler, and  a profiler is just a fancy tool  for measuring. I find some set of steps to  reproduce the program being  slow. And I run those steps with a  profiler attached, so that I can  get an insight into what my code  is doing while it's running  slowly. I combine that knowledge with  what my program has to do to  accomplish the task at hand, and  I find steps that are happening  and remove them, because the  primary way you make your code  faster is you remove redundant  steps from whatever is that is  calculating. Now, I make the modifications to  the source code, and I repeat  and measure as necessary until  I'm happy with the total result. When I'm doing this type of  performance work, I often find  myself in one of a handful of  scenarios. And these different scenarios  change the way that I go about  testing the code in question to  reproduce the bugs. Sometimes I'm up against a big  performance regression, right?  Everything was moving along  smoothly, then someone checked  something in on our team, maybe  it was me, and performance has  fallen through the floor, and  now we have to go back and find  out what caused this regression. If this regression is very  pronounced, or it's in an area  that I don't think it's likely  to regress again in the  immediate future, I may just  test it with my hands, manually,  with the profiler attached. However, your performance  victories are going to be  hard-won battles, and they can  easily be lost through a slow  stream of regressions. I would encourage all of you to  write automated performance  tests to capture your app's  performance, so that you can  ensure that it's not regressing  over time. Another scenario I often find  myself in, is, are applications  performing the same as it has  been for a long time?  Maybe it is running at 45 frames  a second in some drawing test,  but we expect it to run at 60. It needs to be improved  marginally, and we have reason  to believe through our previous  performance work that we can get  there through spot fixes and  incremental changes. Now, in this type of scenario, I  probably also have automated  tests already in play, because I  understand my performance over  time. And a third scenario, our  application is just suffering  from a poor design and  performance is orders of  magnitude worse than it should  be. We know that we can't improve it  with simple spot fixes, because  we've tried them in the past,  and we are still stuck here with  a very sub-par performance. In a situation like this, you'd  want to do a total performance  overhaul, where you are  redesigning some core part of  the feature, or the algorithms  in question, so that performance  is a primary constraint. And definitely in these cases,  you would have performance tests  to measure that you're actually  hitting your performance  targets.

当你在迭代解决性能问题时，你应该在每一步中测量它，以确保你的性能变化正产生你期望的影响。在解决性能问题之后，您应该再次进行度量，以便与原始基线进行比较，并对应用程序的性能改进了多少进行量化声明。你想和你的老板、同事和你的用户分享这一点。现在，当您考虑为用户提高性能时，您需要考虑我所说的总体性能影响。如果您将应用程序的一个区域的功能和性能提高了50%，但是只有1%的用户会遇到这样的问题，那么其影响力几乎不及将某些其他特性提高10%那么大，而您的所有用户一直使用这些特性。因此，确保不要优化边缘情况，并确保更改会影响所有用户。现在我们如何修复性能缺陷？那么，我们如何修复常见的bug呢？通常，它从用户的某种缺陷报告开始，我们采取这种应用程序不像人们期望的那样运行的报告，并且我们找到某种方法来综合步骤来重现，以便我们能够随意地导致失败。一旦我们这样做了，我们就在程序上附加一个调试器，这样我们就可以看到我们的程序在做哪些事情，同时它又表现得不好。我们结合了代码应该如何工作的知识，根据需要修改代码并消除不希望的行为。我们验证我们没有引入任何不想要的副作用，并且根据需要重复，直到我们完全解决了bug。我用同样的方法修复了性能缺陷。除了使用调试器之外，我还使用了探查器，而探查器只是一种测量工具。我发现了一些步骤来复制程序缓慢。我用附带的分析器运行这些步骤，这样我就可以深入了解代码在缓慢运行时正在做什么。我把这些知识与我的程序要做的事情结合起来，找到正在发生的步骤并移除它们，因为使代码更快的主要方法是从正在计算的任何东西中移除多余的步骤。现在，我对源代码做了修改，我重复和测量必要的，直到我对总的结果感到满意。当我做这种类型的性能工作时，我经常发现自己处于少数几种情况中。这些不同的场景改变了我在测试代码中复制错误的方式。有时候我遇到了很大的成绩回归，对吧？一切都进行得很顺利，然后有人检查了我们团队中的一些东西，也许是我，并且性能已经下降了，现在我们必须回去看看是什么导致了这种倒退。如果这种回归非常明显，或者它位于一个我认为近期内不太可能再次回归的区域，那么我可以用手动测试它，并附带分析器。然而，你的表现胜利将是来之不易的战斗，而且它们很容易通过缓慢的回归流而丢失。我鼓励大家编写自动性能测试来捕获应用程序的性能，以便确保它不会随着时间推移而退化。我经常发现的另一个场景是，应用程序和它一样长时间运行吗？也许在一些绘图测试中，它每秒运行45帧，但我们预期它运行在60。它需要稍微改进，我们有理由相信通过以前的性能工作，我们可以通过现场修复和增量更改来达到目的。现在，在这种场景中，我可能已经使用了自动化测试，因为我理解自己的性能。第三种情况是，我们的应用程序正遭受着糟糕的设计，并且性能比它应该具有的性能低几个数量级。我们知道，我们无法通过简单的现场修复来改善它，因为我们过去已经尝试过它们，而且我们仍然停留在非常低级的性能上。在这样的情况下，您需要进行全面的性能检修，重新设计特性的某些核心部分或相关算法，以便性能成为主要约束。当然，在这些情况下，您将有性能测试来测量您实际达到了性能目标。

 Now, it is important that you  know just what to test. I want to caution you that I  don't ever immediately jump to  these sort of performance  overhauls as a way of fixing a  performance problem. I love to do that. It's sort of Greenfield  engineering, where you get to  design things from the ground  up, but it's very risky. You're going to end up with a  better product at the end, but  it's going to be a turbulent  path getting there as you rework  an entire feature. When you're doing this style of  work, it is imperative you  understand not only the  functional constraints of the  code in question, but also the  performance constraints, and the  typical use patterns that your  users are most frequently  applying to this feature, and  you only get that by having done  performance work in the area in  the past. I'd like to share an anecdote  about our work on a situation  like this, within Xcode. In Xcode 9, we reworked Project  Find, with performance as a  primary goal. It was our goal to deliver  search results in just tens of  milliseconds. When we were going to discuss  this feature with our  colleagues, we were often  challenged to perform searches  across large projects for things  like string, or even the letter  E. Things that produce millions of  results, right?  And certainly if our application  could produce millions of  results quickly, it would be  fast on anything. But if you consider what typical  patterns are, we search for APIs  we use, the names of our own  classes, the names of, you know,  images that we're referencing. Things like that. They produce dozens, maybe  hundreds of results. Certainly, it is essential that  the application works decently  when you get a million results,  but the normal use case is  hundreds of results. Now, some of your work in doing  a task like search is going to  be proportional on things like  generating the raw results, and  other work is going to be based  on how efficiently you can index  the text in the project, and  avoid work in the first place.

现在，重要的是你知道该测试什么。我想提醒您，我不会立即跳过这种性能大修来解决性能问题。我喜欢这样做。这是一个绿色工程，在那里你可以从地面设计东西，但这是非常危险的。你最终会得到一个更好的产品，但是当你重新设计一个完整的特性时，它将会是一条颠簸的道路。当你做这种风格的工作时，你不仅要理解所讨论的代码的功能约束，还要理解性能约束，以及用户最常用于该特性的典型使用模式，并且你只能通过havin来获得这些约束。G曾在该地区做过绩效工作。我想和大家分享一个关于XCKED中关于这种情况的工作的轶事。在XCODE 9中，我们以性能为主要目标重新构建项目查找。我们的目标是在短短几十毫秒内交付搜索结果。当我们要与同事讨论这个特性时，我们经常被要求在大型项目中搜索字符串，甚至字母E。产生数百万结果的东西，对吧？当然，如果我们的应用程序能迅速产生数百万的结果，那么它就快了。但是如果您考虑一下什么是典型的模式，我们就会搜索我们使用的API、我们自己的类的名称、我们所引用的图像的名称。诸如此类。它们产生了几十个甚至几百个结果。当然，当你得到一百万个结果时，应用程序必须正常工作，但是通常的用例是数百个结果。现在，你做搜索等任务的一些工作会与生成原始结果等事情成正比，而另一些工作则会基于你能够如何有效地索引项目中的文本，并首先避免工作。

 In these two scenarios, you're  likely to have completely  different targets for what you  would optimize to make one of  these searches faster than the  other, right?  So it's essential that you  understand how your users are  going to use the product, so  that you can optimize for the  right cases. Now, in all of these cases, I  need to do some form of testing,  whether it's manual, or  automated. I want to share with you two  types of performance tests that  I will typically write to  measure the performance of  Xcode. We will either do unit tests, or  integration tests. Let's compare and contrast them. In a performance unit test, it's  your goal to isolate some  feature of your application and  measure it all by itself. You might mock out its  dependencies, and you might  launch it in a context where it  has been isolated. If I were to write performance  unit tests for Xcode's code  completion, I might write a  series of three small tests. One of these tests would measure  talking to the compiler and  getting the raw results, the raw  set of code completion  candidates back. Another performance test would  measure correlating, ranking and  scoring those results, so we  knew which ones to display to  the user. A third test might take those  already prepared results, and  measure putting them into UI  elements for final display. And in covering all three of  these areas, I would have pretty  good coverage over the major  components of code completion in  the IDE. Now, there are some great  aspects to these performance  unit tests.

在这两种情况中，您可能拥有完全不同的优化目标，以使这些搜索之一比另一搜索更快，对吧？因此，了解用户如何使用产品非常重要，这样您就可以针对正确的情况进行优化。现在，在所有这些情况下，我需要做一些形式的测试，无论是手动测试还是自动测试。我想与大家分享两种类型的性能测试，我通常会编写它们来测试XCODER的性能。我们要么进行单元测试，要么进行集成测试。让我们比较和对比它们。在性能单元测试中，您的目标是隔离应用程序的某些特性并自行测量。您可以模拟它的依赖关系，并且可以在它被隔离的上下文中启动它。如果我要为XCODE的代码完成编写性能单元测试，我可能会编写一系列三个小测试。这些测试之一就是与编译器交谈，获取原始结果，然后返回原始代码完成候选集。另一个性能测试将测量这些结果的相关性、排名和评分，因此我们知道应该向用户显示哪些结果。第三次测试可能会把已经准备好的结果，并将它们放入UI元素中进行最终显示。在涵盖所有这三个领域时，我将对IDE中代码完成的主要组件有很好的了解。现在，这些性能单元测试有一些很好的方面。

 They're going to be highly  focused, which means if they  regress in the future, I'm going  to have a very good idea on  where the regression is, because  the code that is running has  been scoped so well. They are also going to produce  much more repeatable results  from run to run. They're not going to have a big  variance in the times that they  produce. Again, because the code is so  focused. Now, let's contrast that to an  integration test. In an integration test, your job  is to measure the performance of  your application as your users  experience it. Holistically. So, if I was writing code  completion unit tests for Xcode,  I'm sorry, integration tests, I  would launch the full Xcode app. I would open a source file. I would navigate to the source  file, and I would type, and I  would bring up code completion  over and over again. When I profile this, to see what  Xcode is doing, and how much  time it is taking, I am going to  find that this test is anything  but focused and quiet. Xcode is going to be doing  drawing and layout as I type. It is going to be doing syntax  coloring as I type. In the background, it might be  indexing, fetching get status,  deciding to show new files in  the Assistant Editor,  and all of these things are  going to be competing for CPU  resources, along with code  completion.

它们将高度集中，这意味着，如果它们将来回归，我将对回归在哪里有一个非常好的想法，因为正在运行的代码已经得到了很好的范围。它们也会从运行中产生更多可重复的结果。他们不会在他们生产的时间上有很大的差异。再次，因为代码是如此的集中。现在，让我们把它比作一个集成测试。在集成测试中，您的工作是测量用户体验时应用程序的性能。整体上。所以，如果我正在编写XCODE的代码完成单元测试，很抱歉，集成测试，我将推出完整的XCODE应用程序。我会打开一个源文件。我会导航到源文件，然后键入，我会一遍又一遍地提出代码完成。当我分析这个测试时，为了了解Xcode正在做什么，以及花费了多少时间，我将发现这个测试完全不是专注的和安静的。XCODE将在我键入时进行绘图和布局。它将在我键入时执行语法着色。在后台，它可能是索引、获取get状态、决定在助理编辑器中显示新文件，所有这些都将在竞争CPU资源，以及代码完成。

 Maybe when I look in the  Profiler, I'll see that we spend  80% of our time syntax coloring,  and 20% of our time in code  completion. And with this data, I would know  that the best way to improve  code completion performance  would be to defer syntax  coloring. I will never gain that type of  knowledge with a highly focused  unit test. So if I can get everyone here to  take two things away from this  presentation, the second one  should be that your performance  investigations should absolutely  start with these wide  integration tests that measure  how the users experience your  application. So I'm talking about testing,  measuring and profiling. And right now, I'd like to  introduce you to profiling in  Xcode with instruments. Let's head over to the demo  machine. Today we are going to be looking  at a performance problem that we  fixed between Xcode 9 and Xcode  10. I want to show it to you. I'm going to launch Xcode 9, and  open our solar system  application. Now the problem that we are  going to be looking at is  creating tabs. I'm going to just press  Command-T quickly a couple of  times, and as you can see, the  whole screen flashes black, and  it takes several seconds to  create those tabs. That definitely doesn't meet my  expectations as far as  performance goes, and we need to  fix this. So let's take a look at how you  would do that. First, I'm going to launch  Instruments. That is our profiling tool. You can do that from the Xcode  menu, under Open Developer Tool,  Instruments. Now, I'm currently in Xcode 9,  so if I choose this, it's going  to launch the Instruments from  Xcode 9, and of course, I want  the Instruments from Xcode 10,  which I've put here in my doc. So I'm going to hide Xcode, and  bring up Instruments.

也许当我查看Profiler时，会发现我们80%的时间用于语法着色，20%的时间用于代码完成。通过这些数据，我知道提高代码完成性能的最佳方法是推迟语法着色。我不会用高度集中的单元测试来获得这种知识。因此，如果我能让大家从这个演示文稿中带走两点，那么第二点应该是，您的性能调查绝对应该从这些广泛的集成测试开始，这些测试测量用户如何体验您的应用程序。我说的是测试、测量和分析。现在，我想介绍你在XCODE中用仪器分析。我们去演示机吧。今天，我们将研究一个性能问题，我们在XCODE 9和XCODE 10之间进行了固定。我想把它给你看。我将推出XCODER 9，并打开我们的太阳能系统应用程序。现在我们要研究的问题是创建标签。我将快速按下命令T几次，如您所见，整个屏幕闪烁为黑色，创建这些选项卡需要几秒钟。就性能而言，这绝对不符合我的期望，我们需要解决这个问题。让我们来看看你是如何做到这一点的。首先，我要发射仪器。这是我们的分析工具。你可以从XCODE菜单，在开放的开发工具，仪器上做到这一点。现在，我正在Xcode 9中，所以如果我选择这个，它将从Xcode 9启动.ments，当然，我希望从Xcode 10启动.ments，我把它放在我的文档中。所以我要隐藏XCODE，并拿出仪器。

 Now, when Instruments launches,  we're presented with a list of  profiling tools that we could  use to measure our application. There's all kinds of tools here. They can measure graphics  utilization, memory consumption,  IO, and time in general. It can be intimidating to know  which one of these profilers to  start with. I would encourage all of you, if  you just learn one of these  tools, it should be the Time  Profiler. I use it for 95% or more of my  performance work. When your users complain about  your app being slow, they're  complaining about it taking too  long, and long is time. If it turns out that you're slow  because you're doing too much  IO, that is going to correlate  with time, and you will be able  to see this with the Time  Profiler. So if you learn just one  instrument, it should be the  Time Profiler. Let's take a look at how that  works. I'm going to launch the Time  Profiler by just double clicking  on it here, and make Instruments  take the full best op.

现在，当仪器启动时，我们提供了一个可以用来测量应用程序的分析工具列表。这里有各种各样的工具。它们一般可以测量图形利用率、内存消耗、IO和时间。知道这些分析器中的哪一个是很吓人的。我鼓励大家，如果你只学习其中的一个工具，它应该是时间剖析器。我用它做我的95%个或更多的表演工作。当你的用户抱怨你的应用程序很慢的时候，他们抱怨它花的时间太长，时间太长。如果结果是因为IO太多而导致速度变慢，那么这与时间相关，并且您将能够通过时间分析器看到这一点。所以，如果你只学习一种乐器，它应该是时间分析器。让我们看看它是如何工作的。我将在这里通过双击它来启动时间分析器，并使仪器获得最佳的OP。

 Now, we'd like to record Xcode. In the upper left-hand corner of  the Instruments window, you can  control which process you're  going to attach to and record. By default, hitting this record  button would record all  processes on my Mac. I just want to focus on Xcode. I'll switch this popover to  Xcode and hit record. Now, I like to keep an eye on  this area of the window to track  view while I'm recording. So I'm going to resize the Xcode  window to be a little shorter,  so I can still see that, and  then I'm going to do the thing  that was slow. I'm going to create a couple  more tabs. And you can see the graph  changed here. Now, I'm going to go ahead and  quit, and return to Instruments. So what just happened?  While the Profiler was running,  it was attached to our process  like a debugger. And it stopped it, thousands of  times per second, and as it was  stopping it, it gathered back  traces. Now, just a reminder, a back  trace is a description of how  your program got to where it  currently is. So if you're on line 6 of  function C and you got there  because main called A, called B,  called C, then your back trace  is Main, A, B, C. When Instruments captures one of  these back traces, it notes,  hey, we just spent one  millisecond in function C. It says one millisecond, because  that is our sampling interval  for recording once every  millisecond. Now, on the main thread, all  these back traces are going to  start with the Main function,  and they're probably going to  call Application Main, and  they're going to branch out, all  through your source code after  that. We can collapse these back  traces together, and overlay  them into a prefix tree, so they  start at Main and work their way  out.

现在，我们想记录XCODE。在仪器窗口的左上角，你可以控制你要连接到哪个进程并记录下来。默认情况下，命中此记录按钮将记录我的Mac上的所有进程。我只想关注XCODE。我会把这个切换到XCODE和命中记录。现在，我喜欢监视窗口的这个区域，以便在我录制的时候跟踪视图。所以我要将Xcode窗口的大小调整得更短一些，所以我仍然可以看到，然后我要做的是比较慢的事情。我将创建更多的选项卡。你可以看到图表在这里发生了变化。现在，我要走了，退出，回到仪器。刚刚发生了什么事？当分析器运行时，它像调试器一样附加到我们的进程中。它停止了它，每秒数千次，当它停止它，它收集回来的痕迹。现在，提醒一下，回溯是描述程序是如何到达当前的位置的。所以如果你在函数C的第6行，因为main叫做A，叫做B，叫做C，你的回溯轨迹是.，A，B，C。当.ments捕捉到这些回溯轨迹之一时，它指出，嘿，我们只花了1毫秒在函数C上。每个毫秒记录一次的采样间隔。现在，在主线程上，所有这些回溯跟踪都将从Main函数开始，它们可能将调用Application.，然后它们将分支出去，全部通过您的源代码。我们可以一起折叠这些回溯，并将它们覆盖到前缀树中，这样它们就从主干开始，并开始工作。

 And we can bubble up those  millisecond counters that we  captured at the top, so that we  can hierarchically see how much  time was spent in all the  different areas of our source  code. And we are going to look at this  data to try and find redundant  and unnecessary operations that  we can make faster, and that is  our primary method that we are  going to use to improve the  performance of our application. Now, as you can imagine, we're  capturing thousands of back  traces per second. There is an overwhelming amount  of data for you to wade through  in instruments. My primary advice to you is that  you want to filter this data as  much as possible so that you can  see the course grain performance  leads, and not focus on minutia. All right?  So I want to show you how to  apply a bunch of powerful  filters and instruments. So as I did the recording, you  remember, I had the track view  visible. I did that because I wanted to  see how the CPU utilization  changed and where it was  changing, while I was creating  new tabs, and I noted to myself  that it was right here. I simply dragged and selected  over that area of the trace, and  I've caused instruments to only  focus its back trace data on  just that time interval. Everything over here, this is  before I was creating tabs. Everything over here, this is  after I was creating tabs, when  I was quitting the application. That's not what I'm trying to  optimize right now, so I don't  need to see that data. Now, in the bottom area of the  Instruments window, Instruments  is showing me all the traces it  collected. By default, there is one row per  thread that was running. And in this example it looks  like there was only four threads  running.

我们可以把在顶部捕获的那些毫秒计数器泡起来，这样我们就可以分层地查看在源代码的所有不同区域花费了多少时间。我们来看看这些数据，试图找出冗余的、不必要的操作，以便更快地进行操作，这就是我们用来改进应用程序性能的主要方法。现在，你可以想象，我们每秒捕捉数千条回溯。有大量的数据供你涉猎乐器。我给您的主要建议是，您要尽可能地过滤这些数据，以便您可以看到谷物性能引导的过程，而不要关注细节。好吗？所以我想向你们展示如何应用一系列强大的过滤器和仪器。所以，当我做记录时，你记得，我看到了轨道视图。我这么做是因为我想看看CPU利用率是如何变化的，以及它在哪里变化的，当我创建新的选项卡时，我注意到它就在这里。我只是简单地拖拽和选择轨迹的区域，并且我已经使仪器只把其回溯轨迹数据集中在那个时间间隔上。这里的一切，这是在我创建标签之前。这里的一切，这是在我创建标签之后，当我退出应用程序的时候。这不是我目前正在努力优化的，所以我不需要看到这些数据。现在，在仪器窗口的底部，仪器向我展示了它收集到的所有痕迹。默认情况下，每个线程正在运行一行。在这个例子中，看起来只有四个线程在运行。

 Sometimes you'll have much more. Depends on how concurrent your  application is. I often like to collapse these  in the name of focusing, and I  also like to collapse them so  they're based on the top level  functions executing in each of  the threads, rather than the  thread IDs, because that  corresponds better with how I  use Grand Central Dispatch. Down in the bottom of the  Instruments window, I'm going to  click on this button that says  Call Tree, and I'm going to zoom  in on it, so you can see what  I'm about to do. There are several filters  available here. One of them is separate by  thread. It is on by default. I am going to go ahead and  disable that, and instead, all  of the threads are going to be  grouped by their top level entry  point, rather than their thread  ID. Now, looking at this trace, I  can see that of all these  threads running, which by the  way, below the main trace, which  is the aggregate CPU usage, the  CPU usage is broken down per  thread, I can see that almost  all the other threads were  largely inactive during this  trace. I can focus on just the main  thread by selecting it here, and  now I'm only looking at traces  from the main thread during this  time period. I'm ready to start digging into  this call hierarchy, so I can  see what my application was  doing.

有时你会得到更多。取决于应用程序的并发性。我经常喜欢以调焦的名义把它们折叠起来，我也喜欢把它们折叠起来，这样它们就基于每个线程中执行的顶层函数，而不是线程ID，因为这与我如何使用Grand Central Debug更好地对应。在仪器窗口的底部，我会点击这个叫“呼叫树”的按钮，我将放大它，这样你就可以看到我要做什么。这里有几个过滤器可用。其中一个是用螺纹分开的。它是默认的。我将继续并禁用它，相反，所有线程将被它们的顶级入口点分组，而不是它们的线程ID。现在，看这个跟踪，我可以看到所有这些线程运行，顺便说一下，低于主跟踪，这是聚合。吃了CPU的使用，CPU的使用被分解了每一个线程，我可以看到几乎所有其他线程在这一过程中大部分是不活跃的。在这里我可以只关注主线程，现在我只关注这个时间段内主线程的跟踪。我准备开始挖掘这个调用层次结构，这样我就可以看到我的应用程序在做什么了。

 Often, I'll walk this with the  keyboard, by just pressing right  arrow and down, over and over  again. But I'd like to show you the  heaviest back trace inspector  that Instruments offers. If your Inspector is not  visible, you can toggle it with  this button, and the heaviest  back trace will be available  here, in this tab, Extended  Detail. Now, the heaviest back trace is  just the trace that occurred  most frequently. It's the back trace that  happened most frequently while  we were recording under the  current selection. And you can use this to quickly  navigate many frames deep at a  time. I typically look through here,  looking for my own APIs, and  things that would surprise me  for taking up this amount of  time, or for areas where we make  a significant branching point in  the number of samples. Now, looking through here, I see  this call, which is to IDE  Navigator, replacement view, did  install view controller. Now, I'm familiar with this API,  because it's an internal API of  Xcode. And in the trace, I can see over  here on the left-hand side of  the window that it is  responsible for 1.19 seconds of  the total time we're recording,  or 45% of the time. That is far and away above my  expectations for how much this  method should cost. However, it's hard to focus on  what is happening here. Right? I'm, there is all this  other stuff at the bottom of the  trace, and it looks like I'm,  you know, 30 or 40 stack ranges  deep. That can be intimidating. I want to show you how to focus. The first technique is back here  in that call tree popover again. I'm going to use this popover to  choose the flattened recursion. Let's go ahead and do that.

通常，我会用键盘，通过按右箭头和向下，一次又一次。但我想给你们展示仪器提供的最重的回溯探测仪。如果您的检查员不可见，您可以用此按钮切换它，最重的回溯跟踪将在此选项卡Extended Detail中找到。现在，最沉重的背部痕迹只是最常发生的痕迹。当我们在当前的选择下记录时，它是最频繁发生的后跟踪。你可以用这个方法快速地在一段时间内快速地浏览许多帧。我通常在这里浏览，寻找我自己的API，以及那些占用了这么多时间让我感到惊讶的东西，或者那些我们在样本数量上有重要分支的领域。现在，通过这里，我看到这个调用，它是IDE导航器，替换视图，确实安装视图控制器。现在，我熟悉这个API，因为它是XCODEL的内部API。在轨迹中，我可以看到，在窗口的左侧，它负责我们记录的总时间的1.19秒，或者45%的时间。这远远超出了我的期望，这个方法应该花多少钱。然而，很难集中注意力在这里发生的事情。正确的？我，在跟踪的底部还有其他所有的东西，我知道，我知道，30个或40个堆栈范围深。这可能是恐吓。我想告诉你如何集中注意力。第一种技术又回到了调用树POPORE中。我将使用这个PopFor来选择平坦递归。我们去做那件事吧。

 And now you can see that, that  repeated set of method calls  that was right here, oops, has  been collapsed. I'm sorry, let me scroll down. That has been collapsed. In fact, I'm confident that I  want to continue my performance  investigation inside of this IDE  Navigator area, API call, and I  can refocus the entire call tree  by context, clicking here, and  choosing Focus on Subtree. And Instruments is going to take  that symbol up to the top of the  call graph, it's going to remove  everything else, and it is going  to reset the percentages at 100%  so I can focus on just this. Now, I can continue to walk this  sample with the arrow keys to  see what we're doing. And I'm familiar with these  APIs. And it looks like we're doing  state restoration. And as I continue to expand  this, I can see that we are sort  of deep inside the table view,  and in addition to there being  this sort of hot call path, you  know, that is taking large  number of the total percentage,  there's all these other  incidental samples as well. It's easy to get distracted by  these. One of them here is OPC Message  Send. This can occur all over your  tracers if you're writing  objective C. Even if you're writing Swift  code, as you work your way into  the system libraries, you'll see  this. You'll often see its counterpart  functions, OPC, Load Strong,  Load Weak, etc., Retain, you can  remove all that content from the  call tree by context clicking on  it, and choosing Charge OPC to  Callers. That's going to tell Instruments  to take all the samples that  came from lib OPC and remove  them from the call data, but  keep the time as attributed to  the parent frames that called  them.

现在你可以看到，在这里，重复的方法调用，OOP，已经崩溃了。对不起，让我向下滚动。这已经崩溃了。事实上，我确信我想在这个IDE Navigator区域（API调用）内继续我的性能调查，我可以通过上下文、单击这里和选择Focus on Subtree来重新关注整个调用树。仪表将把那个符号带到调用图的顶部，它将移除所有其他内容，它将把百分比重置为100%，所以我可以只关注这个。现在，我可以继续用箭头键来看看这个样本，看看我们在做什么。我对这些API很熟悉。看起来我们正在进行状态恢复。当我继续扩展这个时，我可以看到，我们在表视图的深处，除了有这种热呼叫路径，你知道，占总百分比的很大一部分，还有所有其他的附带示例。很容易被这些注意力分散。其中一个是OPC消息发送。如果您正在编写目标C，那么在跟踪器中会发生这种情况。即使您正在编写Swift代码，当您进入系统库时，您也会看到这一点。你会经常看到它的对应函数，OPC，负载强大，负载弱等，保留，你可以删除所有内容从呼叫树通过上下文点击它，并选择收费OPC到呼叫者。这将告诉.ments从库OPC中获取所有样本，并将它们从调用数据中删除，但要保持与调用它们的父帧相关的时间。

 I tend to treat those objective  C runtime functions as just the  cost of doing business when  writing objective C code. It's rarely the case that I'm  going to attempt to optimize  them out, so I just prefer to  remove them from the data, so I  can focus on the things that I'm  likely to take action on. Another very powerful filter  that you can apply, and one that  I'm going to use to remove all  these small samples that  occurred during this set of  frames, is here in the call tree  constraint section. Let me show you. I'm going to tell Instruments  that I would only like to see  areas of the trace that  accounted for let's say 20 or  more samples. I'm picking 20 because I know  that I've selected about a two  second interval and 20  milliseconds is going to  represent about 1% of the total  work, and that is about the  granularity that I like to work  at by default. So with call tree constraints  set to a minimum of 20, I now  focus this down much more  significantly. Now, I mentioned here that we  were expanding out my view  items. I see that in the fact that  we're calling NS outline view,  expand item, expand children. Now, a lot of people would stop  with the call graph at this  point. They'd see I'm calling into a  system framework, and I'm  spending a lot of time there. This isn't my fault, right?  What can I do about this?  I can't optimize NS Outline  View, Expand Items. You absolutely have the power to  influence these situations. For example, the system  framework could be spending all  of this time because it's  operating on data that you  provided it. It could be taking a lot of time  because you are calling this  method thousands or millions of  times. It could be taking a lot of time  because it's calling back into  your code through delegation. And most importantly, you can  get an insight into what the  system framework is doing by  expanding down through the  Instruments tree, and looking at  the names of functions that are  being called. In fact, that's exactly how I  learned to fix this bug. As I expand the trace into the  outline view, I can see that it  is calling these two methods  here. Batch Expand Items with item  entries, expand children, and do  work after end updates.

在编写目标C代码时，我倾向于将这些目标C运行时函数视为做生意的成本。我很少尝试优化它们，所以我只想从数据中删除它们，这样我就可以集中精力处理可能要采取行动的事情了。您可以应用的另一个功能强大的过滤器，以及我将用来移除这一组帧期间发生的所有这些小样本的过滤器，位于调用树约束部分中。让我指给你看。我打算告诉仪器公司，我只想看到占痕迹面积的20个或更多的样品。我选择20，因为我知道我选择了大约两秒的间隔，20毫秒将代表总工作的1%，这是关于我默认工作的粒度。因此，调用树约束设置为20的最小值，我现在更关注这一点。现在，我在这里提到我们正在扩展我的视图项目。我看到，事实上，我们正在调用NS大纲视图，展开项，展开子项。现在，很多人会在这一点上停止使用调用图。他们会看到我打电话到一个系统框架，我在那里花了很多时间。这不是我的错，对吧？我该怎么办呢？无法优化NS大纲视图，展开项目。你绝对有能力去影响这些情况。例如，系统框架可能花费所有的时间，因为它运行在您提供的数据上。它可能需要很多时间，因为你调用这个方法成千上万次。它可能需要很多时间，因为它通过委托调用回您的代码。最重要的是，你可以深入了解系统框架正在做什么，通过向下扩展通过仪器树，并查看正在被调用的函数的名称。事实上，这正是我学会修复这个bug的方法。当我将跟踪扩展到大纲视图中时，我可以看到它在这里调用这两种方法。批处理扩展项目项，扩展子项，并在结束更新后执行工作。

 Now, those are big clues to me  that there is probably some  opportunity for efficiency  through batching. As you could imagine, the  outline view starts with a small  set of items, and then we are  trying to restore expansion  state in this area of our code,  and so we are telling it to  open, for example, the top item. And when we tell it to open the  top item, internally you might  imagine that it moves all the  other items down. Then you ask me to expand the  second item. It moves all the items down  again. And the third item, and so on. And by the time you're done,  you've moved those bottom items  down thousands of times. That is all redundant work, and  that is exactly the sort of  thing I'm looking to eliminate  when I'm trying to improve  performance. Now the fact of these method  calls talk about batching leads  me to believe that there is  probably some API where I can  ask the outline view to do the  work in bulk so it computes all  the positions just once, instead  of over and over again as I make  the calls. I also see a call that says to  do the work after end updates. Now, sometimes an API will offer  sort of bulk method that  operates on an array, and other  times, it will offer a sort of  transactional API that says I'm  going to begin making changes,  then you make a bunch of  changes, and then you say you're  done, and it computes something  that happened for the whole  range of your changes, more  efficiently than if it had done  them all individually. So at this point, I would head  over to the NS Outline View, or  NS Table View API, and I would  look for some such method. And there is exactly one there. In NS Table View, there is  methods for beginning and end  updating, that allow the table  view to coalesce, and make all  this work significantly more  efficient. Of course, we adopted that in  Xcode 10. Let me show you.

现在，这些都是我的一个重要线索，可能有效率的机会，通过批处理。可以想象，outline视图以一小组项目开始，然后我们试图恢复代码中这个区域的扩展状态，因此我们要求它打开，例如，顶部项目。当我们告诉它打开顶部项目时，在内部，你可能会想象它会把所有其他项目都放下。然后你让我扩大第二项。它再次移动所有的项目。还有第三个项目，等等。当你完成的时候，你已经把那些底部的东西移了几千次了。这些都是多余的工作，而这正是我在努力提高性能时希望消除的那种工作。现在，这些方法调用谈论批处理的事实使我相信可能有一些API，我可以要求大纲视图批量地完成工作，因此它只计算一次所有位置，而不是在我调用时一次又一次地计算所有位置。我也看到了一个呼叫，说在结束更新后做这项工作。现在，有时一个API会提供某种在数组上操作的大容量方法，有时，它会提供某种事务性API，表示我将开始进行更改，然后进行一些更改，然后您说已经完成了，然后它计算发生了什么。改变整个范围，比单独完成变化更有效。因此，在这一点上，我将指向NS大纲视图或NS表视图API，并且我会寻找一些这样的方法。那里正好有一个。在NS表视图中，有一些用于开始和结束更新的方法，允许表视图进行合并，并使所有这些工作明显更有效。当然，我们在XCODE 10中采用了这种方法。让我指给你看。

 I'm going to launch Xcode 10. I'm going to open the source as  an application, and I'm going to  create a couple of tabs. And you can see, there is no  awful flashing, and the tabs  open much more quickly. Now, I'd like the tabs to open  even quicker than that, right?  So what am I going to do next?  I got lucky here. It's not every day that you're  going to go into the trace, and  find something so obvious and  easy to fix, that is responsible  for 50% of the sample. Right? In fact, there is not  going to be any other huge lead  sitting there waiting for me. Instead, what I'm going to need  to do is go through that whole  sample, with those course  filters applied, so I'm only  looking at operations that take  about 1% of the time or more,  and I'm going to look for every  single thing that I see that I  think I can come up with some  mechanism for making a little  bit faster. I'm going to note them all down  on a piece of paper or in a text  document or something, and then  I'm going to start solving them. Now, I need to pick an order to  solve them in, right?  Because sometimes the fifth  thing on the list, fixing it  with an obsolete, whatever fix  you would do for the second  thing on the list, and it feels  bad to do them in the wrong  order, such that you did  redundant work, because that's  the whole thing we're trying to  remove in the first place, is  redundant work. But it's very hard to predict  how these things are all going  to play out. And you often can't know until  you've already done the work. So do not let this stop you from  getting started, because you're  going to get your second 30%  improvement by stacking 10 3%  improvements. Okay?  Now, I want to go back to the  slides, and show you some of the  techniques we typically use to  make those continued  improvements. Far and away, the thing that  comes up the most frequently is  using those same techniques the  outline view was using. Batching and deferring, right?  You have an API, and when the  API is called, it has some side  effect. And then you have some code  calling your API in the loop. That's what you're doing-- the  primary piece of work that is  being requested, and having a  side effect. Well, if no one was reading the  result of the side effect, then  you're doing that work  redundantly, over and over  again. You can often get a much more  efficient interface by using a  batch interface, where a client  gives you an array or some sort  of collection of all the work to  be done, so that you can compute  that side effect just once. Now, sometimes you have many  clients, right?  And they can't batch across each  other, and you can get even--  you can still get that same  style of performance through  deferring the work and doing it  lazily. A third easy way to improve  performance is you look through  that instrument's trace, is to  find areas where you see the  same thing being computed over  and over again. For example, you have a method  in its computing, the size of  some text, then you see the same  thing happening several frames  later, for the same text, and  again, and again. Now, in this situation, of  course, you want to try to just  compute that value one time. Compute it at the top, and pass  it down or maybe cache it. Another technique you have  available in your UI  applications is considering how  many views you are using to  render your UI. It can be very great for your  source code organization to use  very small views, with small  sets of functionality, and to  compose them together into  larger pieces. But the more views you use, the  harder you tax the rendering and  layout systems. Now, this is a two-way street,  because smaller views often led  you to have more fine-grain  caching, which can be good for  performance as well. But generally, you can tweak the  number of views that you have in  order to have a significant  impact on performance. It is not always best to have  fewer views, otherwise all of  our applications would just have  one giant view for the whole  thing. Another technique that comes up  pretty frequently is using  direct observation. We often have two areas of our  source code that are loosely  coupled. Maybe one area knows about the  other, and they're communicating  with each other through some  indirect mechanism. Maybe they're using NS  Notification Center, some  block-based call backs,  delegation, or key value  observing. Now something that I see very  frequently is we'll have some  model code, and it's going in a  loop, being changed, and every  time it is going to that loop,  it is firing lots of KVO  notifications. You can't actually see that in  the model code, of course, but  over in some other controller,  it's madly responding and trying  to keep up with whatever is  changing in the model, and  you're burning lots of CPU time  doing this, that ends up being  redundant when you consider the  whole scope of changes.

我要启动XCODE 10。我将打开源作为一个应用程序，我将创建几个选项卡。你可以看到，没有可怕的闪光，而且标签打开得快得多。现在，我想把标签打开得比这个还要快，对吧？那下一步我该怎么办？我在这里很幸运。你并不是每天都要去寻找痕迹，发现一些显而易见、易于修复的东西，而这些东西占了样品总数的50%。正确的？事实上，坐在那里等我的人不会有其他的大人物。相反，我需要做的是遍历整个样本，应用那些过程过滤器，所以我只查看花费大约1%或更多时间的操作，并且我要查找我看到的每一件事，我认为我能够想出一些机制来做mak。稍微快一点。我会把它们全部记录在一张纸上，或者文本文件上，或者别的什么东西上，然后我会开始解决这些问题。现在，我需要选择一个订单来解决它们，对吧？因为有时候清单上的第五件事，用一个过时的，无论你对清单上的第二件事做什么，来修正它，而且按照错误的顺序去做它们会让你感觉很糟糕，这样你就做了多余的工作，因为这是我们首先要删除的全部内容，是多余的工作。但是很难预测这些事情会如何发展。直到你已经完成这项工作，你才能知道。所以，不要让这些阻碍你开始，因为通过叠加103%的改进，你将得到第二个30%的改进。可以？现在，我想回到幻灯片上，向您展示一些我们通常用来进行持续改进的技术。远处，最经常出现的事情是使用大纲视图所使用的那些技术。分批递延，对吗？你有一个API，当API被调用时，它会产生一些副作用。然后你有一些代码在循环中调用你的API。这就是你正在做的——被请求的主要工作，并且有副作用。如果没有人读到副作用的结果，那么你就一次又一次地重复这项工作。您通常可以通过使用批处理接口来获得更有效的接口，其中客户机为您提供一个数组或所有要完成的工作的某种集合，以便您只需计算一次副作用。现在，你有很多客户，对吧？而且他们之间不能互相纠缠，你也可以做到公平——通过推迟工作并懒洋洋地去做，你仍然可以得到同样的表现。提高性能的第三个简单方法是仔细检查仪器的轨迹，找到重复计算同一事物的区域。例如，在计算中有一种方法，某个文本的大小，然后您会看到同样的事情在几帧之后发生，对于相同的文本，一次又一次。现在，在这种情况下，当然，你想尝试一次计算这个值。在顶部计算它，并把它传递下来，或者缓存它。您在UI应用程序中可用的另一种技术是考虑使用多少视图来呈现UI。对于您的源代码组织来说，使用非常小的视图、具有少量的功能集，并将它们组合成较大的片段，这是非常棒的。但是使用的视图越多，对绘制和布局系统的征税就越难。现在，这是双向的，因为较小的视图常常导致您有更多的细粒度缓存，这对性能也有好处。但通常，您可以调整您所拥有的视图数量，以便对性能产生重大影响。视图不总是最好的，否则我们所有的应用程序都只能有一个大视图。另一种经常出现的技术是直接观察。我们的源代码通常有两个区域是松散耦合的。也许一个区域知道另一个区域，它们通过一些间接机制互相交流。也许他们正在使用NS通知中心，一些基于块的回调，委派，或关键值观察。现在，我经常看到，我们将有一些模型代码，它进入一个循环，被改变，每次进入那个循环，它都会触发许多KVO通知。当然，在模型代码中看不到，但是在其他一些控制器中，它疯狂地响应并试图跟上模型中任何变化的步伐，并且您为此消耗了大量的CPU时间，当您考虑到变化。

 Now, if this was direct callouts  from the model code, either  through notifications,  delegation or manual block-based  call backs, it would be much  more obvious that this was  happening as you edited that  model code. And you might decide that it is  totally appropriate to pull some  of those notifications out from  inside the loop to outside the  loop, to have a big impact on  performance. Now, alternatively, on the  controller side, you could use  one of these deferring and  batching techniques to avoid the  redundant work and just not  respond synchronously. Last, this is an easy one. Once your code is already on the  [inaudible] happy path, you  know, it's already linear, and  it's not going to get any better  than linear. That's sort of the minimum  performance that you're going to  get. You're after all the constant  time improvements that you can. Now, an easy one is that if  you're using dictionaries like  they were objects, then you  probably know you're doing this,  if you have a bunch of string  constants for all the keys, then  you can get a big improvement to  code clarity, to code  completion, to re-factoring, to  making the validating your  source code, by using specific  types. It couldn't be easier with  strucks and swift with their  implicit initializers and  conformance to equitable hash. And this can just be hands-down  an improvement to your source  code, and you'd be surprised at  how much time you're spending in  string hashing and string  equation if you were doing this  millions of times on lots of  small objects. So with that, I'd like to turn  it over to Matthew to talk to  you about how we've applied  these techniques inside of  photos.  Thanks Jim. Hi everyone. I'm Matthew Lucas, an engineer  in the photos team, and today I  want to give you some practical  examples on performance from  directly from photos. So first, let's talk about  photos for a second. We are all familiar with this  app. It lets you store, browse, and  experience your favorite  moments.

现在，如果这是通过通知、委托或基于块的手动回调直接从模型代码中调用，那么在编辑模型代码时，这种情况将更加明显。你也许会认为，将这些通知中的一些从循环内部拉出来放到循环外部，对性能有很大的影响是完全合适的。现在，在控制器端，您可以使用这些延迟和批处理技术中的一种来避免冗余工作，而不会同步响应。最后，这是一个简单的例子。一旦你的代码已经走上了[听不见]快乐的道路，你知道，它已经是线性的，并且不会比线性更好。这是你将得到的最低性能。你可以在所有时间上不断改进。现在，一个简单的方法是，如果你像使用对象一样使用字典，那么你可能知道自己正在这样做，如果你对所有键都有一组字符串常量，那么你就可以在代码清晰度、代码完成、重新分解和制作验证方面得到很大的改进。通过使用特定的类型来生成源代码。对于结构化和快速化，它们的隐式初始化器和一致性散列的一致性是不容易的。这只是对源代码的一种改进，如果您在许多小对象上进行数百万次这样的处理，那么在字符串散列和字符串等式上花费的时间就会惊讶不已。因此，我想把它交给马修，跟大家谈谈我们是如何在照片中应用这些技术的。谢谢吉姆。大家好。我是Matthew Lucas，照片组的工程师，今天我想从照片中直接给你们举一些关于性能的实际例子。首先，让我们先讨论一下照片。我们都熟悉这个应用程序。它可以让你存储、浏览和体验你最喜欢的时刻。

 So you can browse your favorite  moments from the moments view,  that you can see here. It's is the default view. But you can also get another  view from the collection, or the  years. And I'll talk more about this  view later. Now, libraries today can go from  1,000 to 100,000 assets previous  depending on your love for  photography. And we all love capturing those  fun and precious moments we live  every day. So we are patient enough to  capture them, but we are less  patient when something like this  appears. How would you feel if something  moments like this would be  displayed in Photos the first  time you launch the app?  Now, you may also experience  something like this, where we  are showing a lot of  placeholders, and that's really  not great. Maybe you're soft scrolling,  you'll be lost in this gray  area, the [inaudible] would  start to load, but then you'll  keep scrolling and then you'll  experience some frame drops  because the views are being  updated. Well, our goal is to not show  views like this. We think this is not providing a  great user experience, but we  understand that sometimes it's  unavoidable. But when it's too frequent, this  isn't really great. Now, when you work on an app,  you want to make sure that it's  responsive, and usable at once.

所以你可以浏览你最喜欢的时刻，你可以在这里看到。这是默认视图。但你也可以从收藏品或年份得到另一个视图。我稍后再谈这个观点。现在，图书馆可以从1000到100000的资产，这取决于你对摄影的热爱。我们都喜欢捕捉我们每天生活的那些有趣和珍贵的时刻。所以我们有足够的耐心去捕捉它们，但是当这样的事情出现时，我们就没有耐心了。当你第一次启动应用程序时，如果像这样的瞬间会出现在照片中，你会有什么感觉？现在，你也可能体验到这样的事情，我们展示了很多占位符，这真的不太好。也许你是软滚动，你会迷失在这个灰色区域，[听不见]会开始加载，但随后你会继续滚动，然后你会经历一些帧下降，因为视图正在更新。我们的目标是不显示这样的观点。我们认为这不是提供一个伟大的用户体验，但我们理解有时它是不可避免的。但是，当它太频繁，这不是真的很好。现在，当你在一个应用程序上工作时，你要确保它是响应性的，同时也是可用的。

 You also want to make sure that  the animations are smooth. And these two attributes are  really crucial to providing a  great user experience. If the users don't find your app  relatable or pertinent, they  might stop using it. Now, to illustrate these two  points, I would like to give you  two examples. And the first one is going to be  how we optimize launching to  this moment view. The second one is how we build  the collections and years view  for good scrolling preference. First, let's do launching  [inaudible]. So what is launch?  There are three kinds of  launches. The first and more expensive one  is the find referred as called,  and it depends the first time  you are going to relaunch your  app after it reboots. So basically, nothing has been  cached yet, and it might require  some bug run processes or some  libraries to load. Now, it also happens when the  system goes under memory  pressure and starts reclaiming  some memory. Now, if you kill an app, it  might not trigger a code launch,  because the system decides when  the resources should be paged  out. And when you kill an app, and  you relaunch it a few second  later, it's almost guaranteed  that you'll hit a warm launch. And we call it warm, because the  resources or the dependents are  still in the cache, so it's  faster to launch. Now, the last type is-- we call  it hot, and it's basically a  resume, because it's when your  app is already running and is  being brought back to the  foreground. So when you start measuring  launch, you should start by  measuring the warm launch. And the time it takes to launch  during this warm is less  variable than the cold launch,  and the test iteration is much  faster as you don't need to  reboot your device.

你也要确保动画是平滑的。这两个属性对提供用户体验至关重要。如果用户没有发现你的应用程序是可取的或相关的，他们可能会停止使用它。现在，为了说明这两点，我想给你们举两个例子。第一个将是我们如何优化发射到这个时刻。第二个是如何建立良好的滚动偏好的集合和年份视图。首先，让我们启动[听不见]。那么发射是什么呢？发射有三种。第一个也是更贵的就是所谓的“查找”，这要看你第一次重新启动应用程序时它是否正常。基本上，什么都没有被缓存，它可能需要一些bug运行过程或一些库来加载。现在，当系统在内存压力下开始恢复一些内存时，也会发生这种情况。现在，如果您杀死一个应用程序，它可能不会触发代码启动，因为系统决定何时应该调出资源。当你杀了一个应用程序，几秒钟后你重新启动它，它几乎保证你会遇到一个温暖的发射。我们称之为“温暖”，因为资源或依赖者仍在缓存中，因此启动速度更快。现在，最后一种类型是--我们称之为热门，它基本上就是一份简历，因为这是你的应用程序已经运行并被带回前景的时候。所以，当你开始测量发射时，你应该开始测量温暖的发射。在暖启动期间启动所需的时间比冷启动时变化小，并且测试迭代要快得多，因为您不需要重新启动设备。

 Now, the way we measure launch  is by evaluating the time it  takes from the moment you hit  the application icon, and until  you can start interacting with  the app. And what I mean by interacting  is that it's really using and  not interacting with a spinner. A common pattern is to dispatch  some work and display a spinner  in the meantime, well that  doesn't make the app usable  sooner, so we are trying to  avoid that here. Now there are three goals that  we are shooting for at Photos,  and the first one is that we  want to instant, we don't want  to display any spinner, and we  don't want to display any  placeholder or [inaudible]. And I Have to be honest with  you, we-- you might see some  placeholders the first time you  synchronize with iClub, but when  the data is local, we really try  our best to not display any. Now, what do we mean by instant?  Well, the time it takes to  launch should be the same time  as the zoom animation from the  home screen. That is usually between 500 and  600 milliseconds, and that way,  the transition from the home  screen to the application is  seamless for the user, and the  user can start interacting with  it, as soon as the animation is  done. And by the way, this is the  lowest recommendation, not  something just for photos, so  it's valid for any apps.

现在，我们衡量启动的方法是评估从点击应用程序图标到开始与应用程序交互所需的时间。我所说的交互是指它真正使用而不是与纺纱器相互作用。一种常见的模式是分派一些工作，同时显示一个旋转器，但这并不能使应用程序更快可用，所以我们试图避免这种情况。现在我们要为Photos拍摄三个目标，第一个是我们想要瞬间，我们不想显示任何旋转器，我们不想显示任何占位符或[听不见]。而且我必须对你说实话，我们--你可能会在第一次与iClub同步时看到一些占位符，但是当数据是本地数据时，我们确实尽力不显示任何占位符。现在，我们指的是瞬间？嗯，发射所需的时间应该与主屏幕上的变焦动画相同。通常为500至600毫秒，这样，从主屏幕到应用程序的转换对于用户来说是无缝的，并且一旦动画完成，用户可以开始与之交互。顺便说一句，这是最低的推荐，而不是照片，所以它对于任何应用程序都是有效的。

 Now, let's look at how photos  launches today. If we look more closely at what  is happening exactly, you can  see that photos is all set up  and ready before the animation  is done. And if we dive into the launch  anatomy, you will see there is  mainly two parts. The first part is being spent in  DYD, this is the loader that is  going to load and link all of  your dependent libraries, but  it's also going to run your  static initializers. And your control over that part  is limited, but it's not  impossible. I would encourage you to watch  the DYD session from last year  in order to get more details on  that part. Now DYD is also calling Main in  your object table, which leads  us to the second part here,  where you have lots of control  over, and this part, you need to  make sure that it stays under  500 milliseconds. Now, the first [inaudible] pass  that is being scheduled right  after the Did Finish launching  will mark the end of your  launch, and this is basically  when your app should be usable. There are a few principles that  we will be referring to during  this session, and these are  really the common pillars of the  performance work that we  achieved. The first one is that we want to  be lazy and defer the work that  we don't need. The second one is that we want  to be proactive, and it's valid  for two things.

现在，让我们来看看今天的照片是如何发行的。如果我们更仔细地观察到底发生了什么，你可以看到，在动画制作完成之前，照片已经整理好了。如果我们跳入发射解剖，你会看到主要有两部分。第一部分是在DYD中花费的，这是加载器，它将加载并链接你所有的依赖库，但是它也将运行你的静态初始化器。你对那部分的控制是有限的，但这不是不可能的。我希望你能从去年开始看DYD会议，以便了解更多的细节。现在，DYD还在你的对象表中调用Main命令，这引领我们到这里的第二部分，在这里你有很多控制权，这部分你需要确保它保持在500毫秒以下。现在，在.Finish发布后安排的第一次[听不见]通过将标志着您的发布结束，这基本上是应用程序应该可用的时候。我们在本届会议期间将参考一些原则，而这些原则正是我们绩效工作的共同支柱。第一个是我们要懒惰，推迟我们不需要的工作。第二个是我们要积极主动，这对两件事是有效的。

  Now, let's see how we optimize  each of these steps for Photos,  and let's start with  initializing the database. So first, usually, the database  is initialized and loaded when  the first query is being fired. One optimization that we have  found was to do it as early as  possible in the background  thread, so that it doesn't have  to do the initialization when  the first query has been fired. And this is an issue, especially  if the first query is being done  from the main thread. Now, we spend a lot of time and  we are still spending a lot of  time reviewing all the queries  that we're doing during launch,  and we want to make sure that  the work that we are doing is  only the necessary one, and we  are not doing more. Now, lastly, we want to ensure  that all the queries that we are  doing are efficient as possible,  and we want to avoid the complex  query as much as possible as  well. And we sometimes we understand  that we need this, and for these  cases, we are setting up some  indexes, so that we can speed  them up. Now we are aiming for, at most,  30 milliseconds spent in that  initialization. So next, let's look at how we  are preparing our view  controllers. So we have four tabs  representing the main features  of the app. And so the first thing that we  need to be careful of is we want  to minimize the work that is  being done in the initialization  of these three non-visible ones,  and the rule that we are trying  to follow here is to do as  little work as possible in the  initializers. We really want to do the bare  minimum, and note all the data  in the view that loads. This also allows us to  initialize our controllers in  constant time. Now, lastly, we also want to  ensure that only the visible  views are loaded. It's easy, and we often regress  on that part, so you should  really be careful about that. So preparing the view  controllers, we are now aiming  for 120 milliseconds. But preparing view controllers  implies configuring the data  sources, and let's look at that  chunk next. So the Moments view is a  representation of these things,  events in your life, and the UI  represents that by having this  group of photos, and these  headers. In this library, for example, we  might have 500 moments, and in  order to build a view, we need  to load all the moments up  front. But the only thing we need  really for these moments is only  the meta data so we can build  the view.

现在，让我们看看如何优化这些步骤中的每一个步骤，让我们从初始化数据库开始。首先，通常在初始化第一个查询时初始化并加载数据库。我们发现的一个优化是在后台线程中尽可能早地进行初始化，这样当第一个查询被触发时，它不必进行初始化。这是一个问题，特别是如果第一个查询是从主线程完成的。现在，我们花费了大量的时间，并且仍然花费了大量的时间来检查我们在启动期间所做的所有查询，并且我们希望确保我们正在做的工作仅仅是必要的，并且我们不会做更多。现在，最后，我们希望确保我们所做的所有查询都尽可能有效，并且我们也希望尽可能避免复杂的查询。我们有时理解我们需要这个，对于这些情况，我们正在建立一些索引，以便加快速度。现在，我们的目标是，最多，在该初始化中花费30毫秒。接下来，我们来看看我们是如何准备视图控制器的。因此，我们有四个标签代表了应用程序的主要特点。因此，我们首先需要注意的是，我们要尽量减少初始化这三个不可见对象时所做的工作，我们试图遵循的规则是在初始化器中尽可能少地进行工作。我们真的想做最低限度，并注意所有数据在视图中的负载。这也允许我们在恒定的时间内初始化控制器。最后，我们还希望确保只加载可见的视图。这很容易，我们经常在那部分倒退，所以你应该非常小心。因此，准备视图控制器，我们现在的目标是120毫秒。但是准备视图控制器意味着配置数据源，让我们看看下一个块。因此，Moments视图就是这些事物、生活中的事件的表示，而UI则通过拥有这些照片和标题来表示它们。例如，在这个库中，我们可能有500个时刻，为了构建视图，我们需要将所有时刻加载到前面。但是我们真正需要的只是这些元数据，所以我们可以构建视图。

 We don't need your content. So the first thing we do is we  fire that query, which is super  fast. And then we are only loading the  content that we need here. In that case here, we are only  going to load the visible  content, which in our case is  going to be between 7 to 10  Moments. Since our deficit is limited,  and finite, we can allow  ourselves to do it synchronously  on the main thread. Now, we also want to anticipate  and schedule the work so that we  can start loading the remaining  data as synchronously. And we do that on the bug run  thread, with the right quality  of service to make sure that it  doesn't preempt the main thread  from running. Now we are aiming at 100  milliseconds here. So lastly, our data sources are  also providing some images and  let's see how we optimize that  part. So this was by far the biggest  chunk here that we are all  attacking, and when we realized  that we were spending multiple  seconds loading this image  during launch, we realized that  we were doing too much work. So the first thing that we did  is that we evaluated the number  of images that we needed during  launch, and we are only loading  that during that first  transaction. In that case, that can be up to  60 including some piling above  and below. And next, in order to load those  images firstly, we need to make  sure that we are all loading  only low-resolutions one. That way we are loading fewer  pixels in memory, and it is much  more efficient. That chunk is now representing  200 milliseconds. And this is, by far, the biggest  gain that we had.

我们不需要你的内容。所以我们首先要做的就是激发这个查询，这是超快的。然后我们只加载这里需要的内容。在这种情况下，我们只加载可见内容，在我们的情况下，它将在7到10个时刻之间。由于我们的赤字是有限的，有限的，我们可以允许自己同步地在主线上进行。现在，我们还希望预测和安排工作，这样我们就可以开始同步加载剩余的数据。我们在bug运行线程上执行此操作，使用正确的服务质量确保它不会抢占主线程的运行。现在我们瞄准的是100毫秒。最后，我们的数据源也提供了一些图像，让我们看看如何优化这一部分。所以这是迄今为止我们所有人攻击的最大部分，当我们意识到我们在发射过程中花了多秒钟加载这个图像时，我们意识到我们工作太多了。所以我们做的第一件事就是我们评估了启动过程中需要的图像数量，并且我们只是在第一笔交易中加载这些图像。在这种情况下，可以高达60，包括一些打桩上面和下面。接下来，为了先加载这些图像，我们需要确保我们只加载低分辨率的图像。这样我们就可以在内存中加载更少的像素，而且效率更高。该块现在代表200毫秒。到目前为止，这是我们最大的收获。

 Which I need to be a constant  time, and that's really great. Now, sometimes you have to ask  yourself the question, is this  really needed during launch?  And one of our examples here is  this footer view. That pulls information via the  network or the database, and  literally first our design was  to not show it during launch. To prioritize all the images  that we are seeing here. We wanted to show as much images  as possible. So that may be simpler. We are now only scheduling that  work post-launch, and we cache  to process information for  raising later. Now, if we would have had the  requirement of displaying this  information, one approach could  have been to leverage the  register background at refresh  API from UA kit, that will  proactively clear your app so  that you can start preparing  some content when the user is  going to launch your app. So now, that part has gone from  launch, and that saves us 400  milliseconds of CPU time. If we look at the updated  breakdown here, we can see that  we now have only 450  milliseconds worth of work. We are now fitting into that 500  millisecond time window, and  regardless of how things can be  represented concurrently here,  the most important part of that  is to really make sure that you  think about the cost of  preparing your content. And what I mean by think is  really measure it. Now, you should strive for doing  work in constant time,  regardless of the total amount  of data you are loading.

我需要一个固定的时间，这真的很棒。现在，有时你不得不问自己这个问题，这真的需要在发射？我们这里的一个例子是页脚视图。通过网络或数据库来拉动信息，字面上我们的设计是在发射时不显示信息。把我们在这里看到的所有图像排在第一位。我们想展示尽可能多的图像。所以这可能更简单。我们现在只是调度工作后启动，我们缓存处理信息，以提高以后。现在，如果我们需要显示这些信息，一种方法是利用来自UA工具包的刷新API时的注册背景，这样可以主动清除应用程序，以便当用户要启动应用程序时，您可以开始准备一些内容。现在，这个部分从发射中消失了，这节省了我们400毫秒的CPU时间。如果我们看看这里的最新故障，我们可以看到我们现在只有450毫秒的工作。现在我们已经适应了500毫秒的时间窗口，不管这里如何同时表示事物，最重要的部分就是确保您真正考虑准备内容的成本。我的意思是思考是衡量它的。现在，不管你加载的数据总量如何，你都应该努力在恒定的时间内完成工作。

 In our case, really have  unbonded data assets, and we  need to stay constant. Now that we have launched the  app, we need to start using it. And let's see how we did  collections and [inaudible] for  good [inaudible] performance. So as I mentioned earlier, our  users can seamlessly transition  with animation from the Moments,  through the collections, to the  years view. And this is a complex hierarchy. We have thousands of pictures to  display. We need to support live updates,  we need to also support  animation between these layers,  and we also have some gestures. Now, we also have some goals  here. For the experience we want to  provide to our users. The first one is the same as  before, we don't want to have  any spinner. We don't want to have  placeholders, but we also want  to have smooth animations. And by smooth animations, I mean  60 or 120 frames per second,  depending on the screen you're  running on. Now, remember the principles  that we've seen before.

在我们的情况下，真的有无担保的数据资产，我们需要保持不变。现在我们已经启动了应用程序，我们需要开始使用它。让我们看看我们如何收集和[听不见]好[听不见]的表演。因此，正如我前面提到的，我们的用户可以无缝地将动画从“瞬间”到“收藏”，再到“年景”。这是一个复杂的层次结构。我们有成千上万的图片要展示。我们需要支持实时更新，我们还需要支持这些层之间的动画，并且我们也有一些手势。现在，我们也有一些目标。我们希望提供给用户的体验。第一个和以前一样，我们不想要任何纺纱机。我们不想拥有占位符，但我们也希望拥有流畅的动画。通过平滑动画，我的意思是每秒60到120帧，这取决于你正在运行的屏幕。现在，请记住我们以前见过的原则。

 Well, they are all applicable  here. We want to be lazy and defer the  work we donate up front. We want to be proactive, and  catch regressions quickly, but  we also want to be constant in  our layout passes, and  regardless of a lot of data that  we are loading. Now, this time, we also want to  be timely, and we want to  remember the rendering loop  cycle. And what I mean by that is that  I want you to remember that we  only have 8 or 16 milliseconds  to render that frame, so we need  to make sure that we are not  going over that time, otherwise  we would start dropping frames. Now, let's take a step back, and  look at what we are trying to  achieve here. We wanted to have this portable  view, with sections and mini  cells in it. And that is basically what your  Collection view is providing,  right?  Except that in this extreme  case, we are restricting the  limit of what we could achieve  with a basic approach. And that resulted in too many  views, too many layers. But also in an increased layered  complexity, and that also had an  increased memory cost.

嗯，它们都适用于这里。我们要懒惰，推迟我们前面捐赠的工作。我们想要积极主动，并快速捕捉回归，但我们也想在我们的布局传递中保持恒定，而不管我们加载了多少数据。现在，这个时候，我们也想及时，我们要记住渲染循环周期。我的意思是，我希望你们记住，我们只有8到16毫秒的时间来渲染那个帧，所以我们需要确保我们不会超过那个时间，否则我们就会开始掉帧。现在，让我们后退一步，看看我们正在努力实现的目标。我们想要这个便携式视图，里面有切片和小细胞。这基本上就是你收藏的观点，对吧？除了在极端情况下，我们用基本的方法来限制我们所能达到的极限。这导致了太多的观点，太多的层。而且还增加了分层的复杂性，也增加了内存成本。

 So we needed to innovate here,  and we did that by restricting  the number of views drastically  while still using a collection  view. We used a technique more  commonly used in video games,  that is called atlasing. And it basically consists of  combining a set of images into a  single one. We do that efficiently by using  only very small thumbnails  first, then we stamp all the raw  image data on the canvas we are  using as a strip. Now, we use image raw data so  that we can avoid decoding each  thumbnail as we send. So basically we are displaying a  random strip of images. Now, we generate and cache them  on the fly so that we can be  more flexible. And as we render multiple images  into a single one, we are  registering the number of cells,  layers, objects drastically,  which simplifies the layout and  the time spent building it. Now, the separate works well,  but it has trade offs to  consider as well, and this is  one of them. So if someone tries to long  press or force search an item  here, we will need to figure its  position so that we can achieve  the preview correctly. And as we display a single  image, we need to maintain the  mapping of each individual  image, and its render strip. Now, you might be thinking, why  are we generating them on the  fly?  Well, we need to support live  updates, that's the reason.

所以我们需要在这里进行创新，我们通过在仍然使用集合视图的同时大幅限制视图的数量来实现这一点。我们使用了一种更常用于视频游戏的技术，称为AtLink。它基本上是由一组图像组合成一个单独的图像。我们首先使用非常小的缩略图，然后将所有原始图像数据印在我们用作条带的画布上。现在，我们使用图像原始数据，这样我们就可以避免在发送时对每个缩略图进行解码。基本上，我们正在显示一个随机的图像条带。现在，我们生成并缓存它们，以便我们可以更灵活。当我们把多幅图像渲染成一幅图像时，我们就大大地记录了单元格、层、对象的数量，从而简化了布局，简化了构建时间。现在，独立运作良好，但也有权衡考虑，这是其中之一。因此，如果有人试图长时间按下或强制搜索一个项目，我们需要确定它的位置，以便我们能够正确地完成预览。当我们显示单个图像时，我们需要维护每个单独图像的映射及其绘制条带。现在，你可能在想，我们为什么要在飞行中生成它们呢？嗯，我们需要支持实时更新，这就是原因。

 We need also to support  different view sizes. For example, we have landscape  here. But we also have portraits. And also we can do that because  we can [inaudible] because our  user's labor typically grows  organically over a long period  of time, and the cases where we  might need to generate thousands  of them are pretty rare. Now, you may be wondering also  why are we not generating the  whole section then?  Well the answer is that our  design record is to do this cool  animation, where you can see  that the collections are  expanding into their own  sections or collapsing into  group ones, and the other way  around. So if there is one thing that  you should also remember from  that second part is you should  really think about the layout  course of your hierarchy and  measure it. Lastly, you should always think  about performance. At Photos, we care deeply about  it, and this is really part of  our daily job. For more information, you can  come and see us in these three  labs that are mentioned here,  and I hope that you have a great  conference. Thank you.

我们还需要支持不同的视图尺寸。例如，我们这里有风景。但我们也有肖像画。我们也可以这样做，因为我们可以[听不见]，因为我们用户的劳动通常长时间有机增长，而我们可能需要产生数千种劳动的情况非常罕见。现在，你可能想知道为什么我们不生成整个部分呢？答案是，我们的设计记录就是做这个很酷的动画，你可以看到，这些藏品正在扩展到它们自己的部分，或者崩溃到组中，反之亦然。因此，如果你还应该从第二部分中记住一件事，那就是，你应该认真考虑你的层次结构的布局过程，并衡量它。最后，你应该总是考虑性能。在照片上，我们深切关注它，这是我们日常工作的一部分。想了解更多信息，你可以到这里提到的三个实验室来看我们，我希望你们有一个很棒的会议。谢谢您。

