  Good afternoon, everyone. Welcome to our talk on Metal for  Accelerating Machine Learning. My name is Anna Tikhonova, and  I'm an Engineer on the GPU  Software Team. The Metal Performance Shaders  Framework is built on top of  Metal. And it provides GPU accelerated  primitives that are optimized  for both iOS and macOS. We provide primitives for image  processing, linear algebra, and  machine learning. We talked extensively about  inference in our past WWDC  sessions, so I just want to  highlight them here. And this year, we've also added  support for training on both iOS  and macOS. Thank you. We've also added support for  accelerated ray tracing on our  platform, and we had an entire  session on this topic earlier  this week. So, it was titled Metal for Ray  Tracing Acceleration. And the video for the session  will be available online  shortly.

大家下午好。欢迎来到我们关于加速机器学习的讨论。我的名字叫Anna Tikhonova，我是GPU软件团队的工程师。金属性能着色器框架是建立在金属之上。它提供了为IOS和MACOS优化的GPU加速原语。我们为图像处理、线性代数和机器学习提供原语。我们在过去的WWDC会议中广泛地讨论了推理，所以我只想在这里强调一下。今年，我们还增加了对iOS和MaOS的培训支持。谢谢您。我们还在平台上增加了对加速光线跟踪的支持，本周早些时候我们对这个话题进行了整个会议。因此，它被称为金属射线追踪加速。会议的视频不久将在网上发布。

 In this session, I will talk  primarily about machine  learning, specifically training. So, I mentioned training and  inference. Deep learning algorithms consist  of these two phases. The first phase is the training  phase. So, let's use an example where  we want to train a model, to  categorize images into classes  like cats, dogs, giraffes,  etcetera. So, in order to train a model to  recognize cats, we need to feed  it a large number of labeled  images of cats. And same for the rabbits and all  of the other animals you want  your model to be able to  recognize. Training is a computationally  expensive and time-consuming,  iterative process. The result of training are  trained parameters. The trained parameters are  required for the next phase, the  inference phase.

在本次会议中，我将主要讨论机器学习，特别是培训。所以，我提到训练和推断。深度学习算法由这两个阶段组成。第一阶段是训练阶段。因此，让我们用一个例子来说明我们想训练一个模型，把图像分类到诸如猫、狗、长颈鹿等类别。因此，为了训练一个识别猫的模型，我们需要给猫喂大量的猫的标记图像。同样的兔子和所有其他动物，你希望你的模型能够识别。训练是一个计算昂贵和耗时的迭代过程。训练结果是训练参数。所训练的参数需要下一个阶段，即推理阶段。

 This is when your model is  presented with a new image, that  is never seen before, and it  needs to classify it based on  the trained parameters. This is a cat. We now provide GPU acceleration  for both the training and  inference phases. But before I talk about  training, let me tell you about  some enhancements to CNN  Inference we've added this year. We now have support for FP16  accumulation for the convolution  and convolution transpose  primitives. This new feature is available on  devices with an Apple A11 Bionic  GPU. We find that using FP16  accumulation for inference  workloads is more than  sufficient in terms of precision  for many commonly used neural  networks. FP16 accumulation offers better  precision and significant power  benefits. So, please take advantage of it  in your inference workloads. And this is an example of how  you can enable FP16 accumulation  for a convolution primitive. You just need to set the  accumulatorPrecisionOption  property. And now, let's talk in depth  about the main topic of this  session, training neural  networks. And let's start with training  convolutional neural networks. So, here we have a simple,  handwritten, digit recognition  network that takes an image of a  handwritten image as input, and  assigns it to one of 10 classes,  from 0 to 9. In this example, we are  correctly classifying this image  as an image of a digit 7. For inference, we initialize our  network with trained parameters. So, in this example, the trained  parameters add the weights for  the convolution, and fully  connected primitives. The goal of a training algorithm  is to compute these trained  parameters, so the network can  use them to map inputs to  correct outputs during  inference. When we start the training  process, we don't have any  weights. We need to compute them. So, the first step is to  initialize the weights with  small, random numbers. And now we are ready to train  this network. So, let's take a look at all the  steps involved in a training  process. Training is an iterative  process, and each iteration of  training can be divided into  four steps. The first step is the forward  pass. This is when we take an input  and pass it to our network to  produce an output. It's very similar to inference. And next, we need to compute  loss. So, loss intuitively measures  the difference between the  network's output and the ground  truth. The objective of a training  algorithm is to minimize loss. Our next step is the gradient  pass. This is when we propagate this  difference when the network's  output and the ground truth,  back to the network to update  weights. The idea is that as training  continues, our network is  becoming better trained, so it's  better able to map inputs to  correct outputs, which in turn  helps to minimize loss. So, this is an overview and now  let's take a look at each one of  these steps in more detail. The forward pass involves  propagation forward to the  network, to compute an output. As you can see, during this  first situation of training, our  network is not doing so well. It's outputting a result that's  clearly wrong. So, why is it doing so badly?  Well, this is expected.

这时你的模型被呈现出一幅以前从未见过的新图像，并且需要根据训练好的参数对其进行分类。这是一只猫。我们现在提供GPU加速的训练和推理阶段。但是在我谈论训练之前，让我告诉你一些关于我们今年增加的美国有线电视新闻网推理的改进。我们现在有支持FP16的积累的卷积和卷积转置原语。这一新特性可在苹果A11仿生GPU设备上使用。我们发现，对于许多常用的神经网络，使用FP16累加进行推理工作量在精度方面是足够的。FP16的积累提供更好的精度和显著的功率效益。因此，请充分利用它的推理工作量。这是一个例子，你可以如何使FP16的积累为卷积原语。您只需要设置StudioPrimeIsOnDe选项属性。现在，让我们深入讨论本次会议的主题，训练神经网络。让我们从训练卷积神经网络开始。因此，这里我们有一个简单的手写数字识别网络，它以手写图像的图像作为输入，并将其分配到10个类之一，从0到9。在这个例子中，我们正确地将该图像分类为数字7的图像。为了推断，我们初始化我们的网络训练参数。因此，在这个例子中，经过训练的参数增加卷积的权重和完全连接的基元。训练算法的目的是计算这些训练参数，以便网络在推理期间能够利用它们来映射输入以校正输出。当我们开始训练过程时，我们没有任何重量。我们需要计算它们。因此，第一步是用小的随机数初始化权重。现在我们准备训练这个网络。所以，让我们来看看培训过程中涉及的所有步骤。训练是一个迭代过程，每个迭代的训练可以分为四个步骤。第一步是向前传球。这是当我们输入并传递给我们的网络以产生输出的时候。这和推理很相似。接下来，我们需要计算损失。因此，损失直观地测量网络的输出与地面的真实性之间的差异。训练算法的目的是将损失降到最低。我们的下一个步骤是梯度通道。这是当我们传播这种差异时，网络的输出和地面真相，回到网络更新权重。我们的想法是，随着培训的继续，我们的网络正在得到更好的培训，因此能够更好地将输入映射到正确的输出，这反过来有助于最小化损失。这是一个概述，现在让我们更详细地看看每一个步骤。前向传递涉及向前传播到网络，以计算输出。正如你所看到的，在第一次培训的情况下，我们的网络做得不好。它输出的结果显然是错误的。那么，为什么会这么糟糕呢？嗯，这是意料之中的事。

 We just initialized our weights  with some random numbers. We haven't trained the network  to do any better yet. So, now, we need some weight to  quantify how well or how badly  our network is currently doing. So, we can use this information  to improve our weights, so that  hopefully after more iterations  of training, the network can  produce a better result. But in order to know how well  we're doing, we need to know  what the right answers are. So, the ground truth, which I  will call labels from now on, is  an input to the network along  with the input image. So, in this case, it's a vector  of 10 values, where we have 1  for the correct class, Class 7,  and zeros for all the other  classes. The output of the network is our  10 probabilities. One per class. So, as you can see in this first  situation of training, the  network is producing a very low  result for the correct Class 7,  and it's assigning the highest  probability to a Class 9, which  is why the network is returning  9 as the answer. So, now we take all of this  information and we pass it to  our loss primitive. And as I mentioned previously,  loss measures the difference  between the network's output and  the ground truth.

我们只是用一些随机数来初始化我们的权重。我们还没有训练网络做得更好。所以，现在，我们需要一些权重来量化我们的网络目前做得有多好或多坏。因此，我们可以利用这些信息来提高我们的权重，从而希望经过更多的迭代训练，网络可以产生更好的结果。但是为了知道我们做得有多好，我们需要知道正确的答案是什么。因此，地面真理，我将称之为标签，从现在起，是一个输入到网络连同输入图像。因此，在本例中，它是一个10值的向量，其中对于正确的类，我们有1，对于第7类，对于所有其他类，我们有0。网络的输出是我们的10个概率。每班一个。因此，正如您在第一次训练中看到的，网络对于正确的第7类产生了非常低的结果，并且它为第9类分配了最高的概率，这就是网络返回9作为答案的原因。所以，现在我们把所有这些信息传递给我们的损失原语。正如我前面提到的，损耗测量网络的输出和地面的真实性之间的差异。

 And the objective of a training  algorithm is to minimize loss. And now, we also need the second  half of the graph. The second half of the graph  contains gradient primitives for  each responding forward  primitive. The gradient primitives compute  gradients that are needed to  update weights. So, the loss primitive computes  the first gradient, which is a  derivative of a chosen loss  function with respect to its  inputs. And then we take this gradient  and back propagate it, backward  through the network, backward  through the first gradient  primitive in the backward  direction. In this case, it's the SoftMax  gradient primitive. And we use the Chain Rule to do  that. So, the Chain Rule allows us to  back propagate gradients,  backwards through the network. And we're computing these  gradients so that we can update  weights. So, we're computing very small  deltas to apply to the weights,  in each iteration of training. And then we can use these  updated weights in the next  iteration of training, to  ideally produce a lower loss  value, which is what we're  trying to minimize. In practice, any situation of  training, we're not going to  operate on a single image. We're going to operate on a  group or a batch of images. For example, a batch of size 32  or 64. And we need a corresponding  batch of labels, for loss  computation. So, in this case, we have a  batch of labels, was 1 for the  correct class and zeroes  everywhere else. And in each situation of  training, we're going to use a  different batch of images and a  responding batch of labels. So, let's now run through  several iterations of training. For the first batch of images,  we're doing a forward pass,  computing loss, and doing a  gradient pass. And updating weights. So, what happens with the second  batch?  Exactly the same process.

训练算法的目的是将损失降到最低。现在，我们还需要图的后半部分。图的后半部分包含每个响应前向基元的梯度基元。梯度原语计算更新权重所需的梯度。因此，损失原语计算第一梯度，它是所选损失函数相对于其输入的导数。然后，我们取这个梯度，反向传播，通过网络，向后通过第一梯度原语，向后传播。在这种情况下，它是SoftMax梯度原语。我们使用链式法则来做到这一点。因此，链规则允许我们通过网络反向传播梯度。我们计算这些梯度，以便我们可以更新权重。因此，我们在训练的每一次迭代中都计算非常小的增量来应用于权重。然后我们可以在下一次的训练迭代中使用这些更新的权重来理想地产生更低的损耗值，这是我们试图最小化的。实际上，在任何训练的情况下，我们都不会在单一的图像上进行操作。我们将对一组或一批图像进行操作。例如，一批大小为32或64的批次。我们需要一个相应的标签来进行损耗计算。因此，在这种情况下，我们有一批标签，正确的类为1，其他地方为零。在训练的每个情况下，我们将使用不同批次的图像和响应的批次标签。现在让我们通过几个迭代的训练。对于第一批图像，我们正在进行前向传递、计算损耗和梯度传递。更新权重。那么，第二批会发生什么呢？完全一样的过程。

 The forward pass, then we  compute loss, to the gradient  pass, and update weights. And as we go through iterations  of training, we want the loss  for our network to decrease and  the accuracy of the network to  increase. And we continue training until  the loss falls below a  particular threshold and the  accuracy of our network reaches  a desired level. And then we know that the  network is fully trained and now  we can use the computed trained  parameters for inference. And now, let's take a look at  the steps necessary to train a  neural network using the Metal  Performance Shaders Framework. Neural networks are often  described using graph  abstraction. So, in MPS, we enable you to  describe your networks as a  graph. So, the first step is to create  a training graph. Then we need to prepare our  inputs. We need to specify weights. And then we execute the graph.

前向传递，然后我们计算损失，梯度传递，并更新权重。当我们经过反复的训练时，我们希望网络损失减少，网络精度提高。我们继续训练，直到损失低于特定的阈值，网络的准确度达到期望的水平。然后我们知道网络是完全训练的，现在我们可以使用计算出的训练参数进行推断。现在，让我们来看看使用金属性能着色器框架训练神经网络所需的步骤。神经网络经常使用图形抽象来描述。因此，在MPS中，我们可以让你把你的网络描述成一个图表。因此，第一步是创建一个训练图。然后我们需要准备我们的投入。我们需要指定权重。然后我们执行图。

 So, we run the forward paths,  compute loss, do the gradient  pass, and update weights. And training is an iterative  process. It can take many iterations to  train a network. So, we'll also need to know when  we can stop training. So, let's now discuss each one  of these topics in more detail. Let's start with creating a  training graph. So, as I said, in MPS, we enable  you to describe your networks as  a graph using a neural network  graph API. So, here we again have a  visualization of our  handwritten, digit recognition  network. But in this visualization, you  can also see the image notes. They're the small white notes. The image notes are for your  data. For your input, your outputs,  and all of the intermediate  results. They describe how data moves  between different operations. And then, operations on the  data, like convolution and  pooling, are described with your  filter nodes. We support all of the nodes  necessary to create commonly  used neural networks. And now, let's take a look at  how easy it is to use the neural  network graph API. So, here's an example of how you  can create an MPSImageNode using  the neural network graph API. And this is how you would create  a convolution node using the  graph API. And now, for every forward node,  we support a corresponding  gradient node for training. It takes a single line of code  to create a gradient node from  the forward node. So, here is an example of how  you can create a gradient  convolution node from the  convolution node.

因此，我们运行前向路径，计算损失，做梯度传递，并更新权重。训练是一个反复的过程。它可以花费许多迭代来训练网络。所以，我们也需要知道什么时候我们可以停止训练。现在让我们更详细地讨论每一个主题。让我们从创建一个训练图开始。所以，正如我所说的，在MPS中，我们可以用神经网络图形API来描述你的网络图。因此，我们再次有一个可视化的手写数字识别网络。但是在这个可视化中，你也可以看到图像注释。它们是白色的小纸币。图像注释是为您的数据。用于输入、输出和所有中间结果。它们描述了数据如何在不同的操作之间移动。然后，对数据进行操作，如卷积和池化，用过滤器节点来描述。我们支持创建常用神经网络所需的所有节点。现在，让我们来看看使用神经网络图形API是多么容易。这里有一个例子，说明如何使用神经网络图形API来创建一个MPSIMAGENODE。这就是如何使用图形API创建卷积节点的方法。现在，对于每个前向节点，我们支持相应的梯度节点进行训练。需要一行代码从正向节点创建一个梯度节点。这里有一个例子，说明如何从卷积节点创建梯度卷积节点。

 And now, let's build an entire  graph. So, here we have a very small  network. We have a convolution node  followed by a pooling node,  followed by another convolution  node. So, how do we connect these  nodes into a graph?  So, that's easy. We take the result node of --  the result image of one node and  pass it as a source image to the  subsequent node. And here we have an entire  connected graph. And now, let's build a training  graph. So first, we need to add a loss  node to the graph. And now, let's add some gradient  nodes. So, as I said, it takes a single  line of code to create a  gradient node from its  corresponding forward node. And then we connect them as  previously, and now you have a  complete training graph. So, as you can see from this  example, the graph API is very  simple to use.

现在，让我们建立一个完整的图表。所以，这里有一个非常小的网络。我们有一个卷积节点，接着是一个池节点，后面是另一个卷积节点。那么，我们如何将这些节点连接成一个图？所以，这很容易。我们取一个节点的结果图像的结果节点，并将其作为源图像传递给后续节点。这里我们有一个完整的连通图。现在，让我们建立一个训练图。首先，我们需要给图形添加一个丢失节点。现在，让我们添加一些梯度节点。所以，正如我所说的，需要一行代码从它的对应的正向节点创建一个梯度节点。然后我们像以前一样连接它们，现在你有一个完整的训练图。因此，从这个例子中可以看出，图形API是非常容易使用的。

 The graph does a lot for you  automatically. It manages all the intermediate  results, and even the output  image. It minimizes the memory  footprint of your networks, by  aliasing memory for all your  intermediate images, using Metal  heaps. It can also fuse graph nodes. For example, it can fuse batch  normalization and neural nodes. And it can optimize away nodes. For example, it optimizes the  way you can cut nation nodes. The graph also automatically  handles padding and manages  state objects for you, which we  will discuss later in this  session. So, please take advantage of the  graph API. So, now that we know how to  create a training graph, let's  now take a look at the inputs we  need to pass to the graph. And for this, let's take a look  at the encode call we will use  to encode the graph to the GPU. So, as I already mentioned,  we're not going to send in one  image at a time for training. We're going to operate on groups  or batches of images. So, one of the inputs to the  graph, is a batch of images. And as you recall, for every  batch of images, we also need a  corresponding batch of labels  for loss computation. The labels for loss computation  are passed to the graph as  states. So, the code call also takes a  batch of states as input. And now, let's talk about these  batches and states.

图表自动为你做了很多事情。它管理所有中间结果，甚至输出图像。它通过使用金属堆来为所有中间图像混叠内存，从而最小化了网络的内存占用。它还可以融合图形节点。例如，它可以融合批量归一化和神经节点。它可以优化远离节点。例如，它优化了可以切断国家节点的方式。该图还自动处理填充和管理状态对象，我们将在本次会话后面讨论。所以，请利用图形API。现在，我们知道如何创建一个训练图，现在让我们看看我们需要传递给图形的输入。为此，让我们来看看我们将把图形编码到GPU的编码调用。所以，正如我已经提到的，我们不会每次发送一个图像来训练。我们将对组或批图像进行操作。因此，图的输入之一是一批图像。正如你所记得的，对于每一批图像，我们也需要相应的一批标签来进行损失计算。损失计算的标签作为状态传递给图表。因此，代码调用也将一批状态作为输入。现在，让我们来谈谈这些批次和状态。

 What are they?  Let's start with batches. So, batches are just arrays of  images or states. We've added them this year  specifically to support  training. There are two new MPS types for  you to use: MPSImageBatch and  MPSStateBatch. So, here's an example of how you  can create a single image, using  our API. So, here we're creating one from  an existing Metal texture. And this is an example of how  you can create a batch of  images, using our API and append  a new image to the batch, so you  can pass it to the graph. And now, what are state objects?  An MPS state is an opaque data  container. In training, it's frequently  used to capture a state of a  forward node, when it's called. And so, it can later be used by  the gradient node. So, the graph manages all of the  state objects. So, as a developer, you  generally don't need to worry  about states. But it's nice to know how they  work. So, let's use a specific  example. So, let's go back to our  handwritten digit recognition  network. And take a look specifically at  the drop-out and drop-out  gradient nodes. The forward drop-out node drops,  or it zeroes out, values in its  input, with a certain  probability. And then, the dropout state  object captures information  about the forward drop-out  operation, so it can later be  used by the drop-out gradient  node because it used to zero out  values in its input gradient at  the exact same locations as was  zeroed out by the forward  operation. So, as I said, you don't  generally need to worry about  states, because the graph  manages them. But because the labels for loss  computation are passed as states  to the graph, and because they  require user input. So, that's your ground truth or  correct results. You need to create a batch of  labels for loss computation and  pass this batch as input to the  graph. So, this is an example of how  you would create a single label  for loss computation. You first need to create a loss  data descriptor which describes  how the label's data is laid out  in memory.

它们是什么？让我们从批次开始。因此，批处理只是图像或状态的数组。今年我们增加了他们来支持培训。有两个新的MPS类型供您使用：MPSImageBatch和MPSSTATEPATH。这里有一个例子，说明如何使用API来创建一个图像。所以，我们从一个现有的金属纹理中创建一个。这是一个示例，说明如何使用我们的API创建一批图像，并向该批添加新图像，以便将其传递到图表。现在，什么是状态对象？MPS状态是一个不透明的数据容器。在训练中，它经常被用来捕获一个正向节点的状态，当它被调用时。因此，它可以稍后被梯度节点使用。因此，该图管理所有的状态对象。所以，作为一个开发人员，你一般不需要担心状态。但很高兴知道它们是如何工作的。所以，让我们使用一个具体的例子。那么，让我们回到我们的手写数字识别网络。并具体地看看辍学和辍学梯度节点。正向下降节点以一定的概率下降或以其零点输出其值。然后，辍学状态对象捕获关于前向辍学操作的信息，因此它以后可以被辍学梯度节点使用，因为它用于在其输入梯度中与前向操作归零的位置上零出值。所以，正如我所说，你一般不需要担心状态，因为图表管理它们。但是因为丢失计算的标签被作为状态传递给图表，并且因为它们需要用户输入。所以，这是你的事实真相或正确的结果。您需要创建一批用于丢失计算的标签，并将该批作为输入输入到图表中。因此，这是一个示例，您将如何创建一个用于丢失计算的单个标签。首先需要创建一个丢失数据描述符，它描述了标签数据是如何在内存中布局的。

  For example, if you have many  convolution nodes in your  network, the overall size of the  weights for the network can be  quite considerable. And we do not want the weights  for all of your convolution  nodes to be in memory all at the  same time. We want to keep the memory  footprints of your networks as  low as possible. And data source providers come  into play here because they  provide just in time loading and  purging of weights data. So, we load the weights for one  convolution kernel, when we  process it. And then we purge them before  moving on the next convolution. So, here's an implementation of  MyWeights. You need to provide an  initialization method that is  responsible for pulling in  memory and making it ready. And then the graph will call the  load function. And then when the purge method  is called, you can release the  weights. Data source providers are also  essential for training, and we  will discuss this later in this  session.

例如，如果您的网络中有许多卷积节点，则网络的权重的总体大小可能相当大。我们不希望所有卷积节点的权重同时在内存中。我们希望尽可能低的保持你的网络的记忆足迹。数据源提供者在这里起作用，因为它们提供了及时加载和清除权重数据。因此，当我们处理它时，我们为一个卷积核加载权重。然后我们在下一个卷积之前清除它们。所以，这里有一个MyBooad的实现。您需要提供一个初始化方法，负责在内存中插入并准备就绪。然后图将调用负载函数。然后，当调用清洗方法时，可以释放权重。数据源提供者对于培训也是必不可少的，我们将在本次会议后面讨论这一点。

 So, now that we have a training  graph and we've prepared our  inputs and specified weights,  we're ready to execute the graph  on the GPU. To change the [inaudible] graph  on the GPU, we first need to do  the usual Metal setup. We need to initialize our  training graph. So, we have prepared our inputs. And now, let's train a network  on the GPU. Training is an iterative  process. So, we want to set up a training  loop. And we usually want to execute  our graph over a number of  EPOCHS. The number of EPOCHS is the  total number -- is the number of  times we want to iterate over  our entire data set. And we want there to be multiple  iterations in each EPOCH. So, the number of iterations is  the total number of images in  your data set divided by batch  size, like 32 or 64. And now, let's take a look at  each training iteration. In each training iteration, we  encode a batch of images for  training. But we don't want the CPU to  wait for the GPU to finish  running one run of the graph,  with one batch of images before  the CPU can start encoding  commands to the command buffer  for the next run of the graph. We want the CPU and the GPU to  work concurrently. And for this, we're going to use  double buffering. So, in this setup, we're going  to create a counting semaphore  with an initial value of 2. It's because we want only two  encodes to be in flight at the  same time. And then when we enter the  training iteration function,  we're going to call weight on  the semaphore. That's decrementing it.

因此，现在我们有了一个训练图，并且我们已经准备好了输入和指定的权重，我们准备在GPU上执行该图。为了改变GPU上的[听不见]图形，我们首先需要做通常的金属设置。我们需要初始化我们的训练图。所以，我们已经准备好了我们的投入。现在，让我们在GPU上训练一个网络。训练是一个反复的过程。所以，我们想建立一个训练循环。我们通常希望在多个时期执行我们的图表。历元的数目是总的数字——是我们想要在整个数据集中迭代的次数。我们希望每个时期都有多个迭代。因此，迭代次数是数据集中的图像总数除以成批大小，如32或64。现在，让我们来看看每一次训练迭代。在每次训练迭代中，我们编码一批图像进行训练。但是，我们不希望CPU在CPU开始将命令编码到命令缓冲区以供下一次运行图形之前，用一批图像等待GPU完成图形的一次运行。我们希望CPU和GPU同时工作。为此，我们将使用双缓冲。因此，在这个设置中，我们将创建一个初始值为2的计数信号量。这是因为我们只希望两个代码同时飞行。然后，当我们进入训练迭代函数时，我们将调用信号量上的权重。这是在减少。

 So, if the value of the count  has already been decremented to  zero, we wait. Otherwise, we continue. And then we encode our graph,  and the encode call returns  immediately. And a user specified callback is  called, when the GPU is done  running the graph. So, now we know. The GPU is done running the  graph, and the CPU can continue  encoding more work to the GPU,  work that was previously waiting  on the semaphore. So, why are we using double  buffering?  Why not encode more runs of the  graph, to the GPU concurrently?  Well, it takes a lot less time  to encode commands to the  command buffer, than to run the  graph. So, we don't want to encode too  many runs of the graph  concurrently to minimize memory  footprint. Okay, we've talked about  executing the graph. When we execute the graph, we do  the forward pass, we compute  loss, we do the gradient pass,  and the graph will also update  weights. So now, let's talk about weight  updates. As I mentioned, data source  providers are essential for  training. All of your weight updates need  to happen through an optional  update method on a data source  provider. The graph will call the update  method automatically. So, what does the weight update  step actually involve?  Let's take a look. So, recall that we're computing  gradients during the gradient  pass that we can apply small  deltas to the weights, in each  situation of training. How these deltas are applied to  the weights, is described by an  optimizer.

所以，如果计数的值已经减去到零，我们等待。否则，我们继续。然后我们编码我们的图形，并且EnCODE调用立即返回。当GPU运行图形时，调用一个用户指定的回调。所以，现在我们知道了。GPU已经运行完图形，CPU可以继续对GPU编码更多的工作，这是之前等待信号量的工作。那么，为什么我们要使用双缓冲呢？为什么不将图形的更多运行编码到GPU同时进行呢？那么，命令到命令缓冲区的运行时间比运行图表要少得多。因此，我们不想同时编码太多的图的运行，以最小化内存占用。好的，我们已经讨论过执行图。当我们执行该图时，我们执行正向传递，我们计算损失，我们执行梯度传递，并且该图还将更新权重。现在让我们来谈谈重量更新。正如我提到的，数据源提供者是培训必不可少的。所有的权重更新都需要通过数据源提供程序上的可选更新方法来实现。该图将自动调用更新方法。那么，权重更新步骤实际上涉及什么？让我们看一看。所以，回想一下，我们在梯度传递过程中计算梯度，我们可以在每个训练情况下对权重应用小的增量。如何将这些增量应用于权重，由优化器来描述。

 It's just a function that takes  the old weights, the computed  gradients as input, and produces  updated weights as outputs. You will use an optimizer in the  update method of your data  source provider. And we support a number of  different variants of the weight  update step on the GPU,  including Adam, Stochastic  Gradient Descent, and RMSProp. And you can even define your own  custom update weight step if you  prefer. So now, let's take a look at how  to use an optimizer in MPS. So, recall that your data source  provider has an init method. This is where you want to create  your optimizer because you only  want to create it once. And now, let's take a look at  the implementation of our update  method. The update method receives the  source state and gradient state  as inputs. So, the source state contains  the old weights, the gradient  state contains the computed  gradients, and now we can encode  our optimizer with this data,  and the last step is to return  the source state, which now has  the update weights. So, pretty simple. And now we have just one more  step to discuss. So, as I said, training is an  iterative process. It can take many iterations to  train a network. And you will need to know when  to stop training.

它只是一个函数，它将旧的权重、计算的梯度作为输入，并产生更新的权重作为输出。您将在数据源提供程序的更新方法中使用优化器。我们还支持GPU上的权重更新步骤的多种不同变体，包括Adam、随机梯度下降和RMSProp。您甚至可以定义自己的自定义更新权重步骤，如果您愿意的话。现在，让我们来看看如何在MPS中使用优化器。因此，请记住，数据源提供程序具有init方法。这是您希望创建优化器的地方，因为您只想创建一次。现在，让我们来看看我们的更新方法的实现。更新方法接收源状态和梯度状态作为输入。因此，源状态包含旧的权重，梯度状态包含计算的梯度，现在我们可以用这些数据对我们的优化器进行编码，最后一步是返回源状态，它现在具有更新的权重。所以，很简单。现在我们还有一步要讨论。所以，正如我所说，训练是一个反复的过程。它可以花费许多迭代来训练网络。你需要知道什么时候停止训练。

 So, let's now discuss how can  you make this decision in the  context of your training loop?  So, here we again have our  training loop, where we're  training a neural network for a  number of EPOCHS. To check whether you can stop  training, you need to have a  test set of images. So, a test set of images  contains images that are not  used for training. They're only used to evaluate  the accuracy of your network. So, after each EPOCH, you can  optionally wait for the graph to  -- for the GPU to stop running  the graph, and then you can use  the current trained parameters  to initialize an inference  network. And then you can run this  inference network on your test  set, and you can optionally stop  training when the accuracy of  your network on this test set,  reaches a particular level. So, now that we've discussed all  of the steps that are necessary  to train a neural network in  MPS, it's time for a demo. So, as was already mentioned in  the platform State of the Union,  the Metal Performance Shaders  Framework powers Core ML, Create  ML, and Turi Create. To Turi Create is an easy to  use, flexible, high-performance  tool set for creating Core ML  models for tasks such as image  classification, object  detection, recommendations, and  more. For more information on Turi  Create, we want to refer you to  the A Guide to Turi Create  Session Video. We've prepared a demo where we  will be using an -- we'll be  training an object detection  network in Turi Create powered  by MPS. As was mentioned in the platform  State of the Union, this is nine  times faster than without MPS. An object detection network  draws bounding boxes around  recognized objects. So, in this demo, I will be  using a MacBook Pro, with a  connected external GPU. I will be running Turi Create on  the MacBook Pro and I will use  an external GPU to train the  network with MPS. This is a great example of how  you can use an external GPU to  enhance the computational power  of a MacBook Pro. The external GPU we're using is  an AMD Vega GPU. So, in this demo setup, I've  already imported Turi Create,  and preloaded the object  detection network, and a  training data set. So, now let's train this network  for 10 iterations. And now, the entire object  detection network, all the  primitives, the optimizer, the  weight update step, everything  is running on the external GPU.

现在，让我们来讨论一下如何在你的训练循环中做出这个决定？在这里，我们又有了我们的训练循环，我们正在训练一个神经网络。为了检查你是否可以停止训练，你需要有一组测试图像。因此，图像的测试集包含不用于训练的图像。它们只是用来评估你的网络的准确性。因此，在每一个历元之后，您可以选择等待图来为GPU停止运行图表，然后您可以使用当前训练的参数来初始化推理网络。然后，您可以在测试集上运行这个推理网络，并且当您的测试集上的网络精度达到特定级别时，您可以选择停止训练。现在，我们已经讨论了在MPS中训练神经网络所需的所有步骤，现在是演示的时候了。因此，正如在联盟平台状态中已经提到的，金属性能着色器框架为核心ML、创建ML和TURI创建提供动力。Turi Create是一个易于使用的，灵活的，高性能的工具集，用于创建核心ML模型的任务，如图像分类，对象检测，建议，等等。有关Turi Cube的更多信息，我们想向您介绍TURI创建会话视频的指南。我们已经准备了一个演示，我们将使用--我们将在MPS支持的Turi Create中训练对象检测网络。正如在联邦平台状态中提到的，这是没有MPS的九倍。对象检测网络在识别的对象周围画边界框。因此，在这个演示中，我将使用一个MacBook Pro，用一个连接的外部GPU。我将在MacBook Pro上运行Turi创建，我将使用一个外部GPU来与MPS一起训练网络。这是如何使用外部GPU来增强MacBook Pro的计算能力的一个很好的例子。我们使用的外部GPU是一个AMD Vega GPU。因此，在这个演示设置中，我已经导入了Turi Create，并预加载了对象检测网络和训练数据集。所以，现在让我们训练这个网络10次迭代。现在，整个对象检测网络、所有原语、优化器、权重更新步骤，一切都运行在外部GPU上。

 Okay, so we're already done with  10 iterations of training, it  would take more than 10  iterations to train this  network, and we're not going to  do this on stage. But what I'm going to do right  now, is to load a network that  we pretrained in advance, run it  on a test set of images and  visualize some of the results. So, let's take a look. Okay, so here we have a banana,  that's correctly classified as a  banana. And we have a bounding box, and  now we have a perfect breakfast  of a cup of coffee and a  croissant, and very,  mean-looking egg. Okay, so that's it for the Turi  Create demo. Thank you very much. And now, let's switch gears and  talk about training recurrent  neural networks.

好，我们已经完成了10次迭代的训练，要训练这个网络需要10次以上的迭代，我们不打算在阶段上做这个。但是我现在要做的是，加载一个我们事先预习的网络，在一组测试图像上运行它，并将一些结果可视化。那么，让我们来看一看。好的，我们这里有一根香蕉，它被正确地分类为香蕉。我们有一个包厢，现在我们吃了一顿完美的早餐，一杯咖啡，一个羊角面包，还有一个看起来很吝啬的鸡蛋。好了，这就是Turi制作演示。非常感谢你。现在，让我们换个角度谈谈训练递归神经网络。

 But first, let's do a recap of  what are the recurrent neural  networks?  One of the disadvantages of  convolutional neural networks is  their inability to remember  anything that happened  previously. They can take one input, such as  an image, and generate a single  output, such as a set of  probabilities of what is  depicted in the image. RNNs on the other hand, have  memory. And they're good at operating on  sequences of inputs and outputs. For example, they can take one  set of probabilities, so what is  depicted in an image, which is  an output of a CNN, and generate  a sequence of outputs, which is  a sequence of words that make up  a caption for this image. They can also take a sequence of  inputs, such as a sequence of  words that make up a sentence  and generate a sequence of  outputs which is a same sentence  but translated to a different  language. For example, to ration or  finish. With support, a number of  different variance of RNNs. The most commonly used one is  the Long Short-Term Memory RNN,  or LSTM for short. In our last year's WWDC Session,  we talked extensively about the  gates inside LSTM and walked  through a LSTM inference  example. So, please refer to that session  for more information on LSTM  inference. This year, we've added support  for training, for all of these  variants of RNNs. And in this session, I'm going  to talk about training LSTMs. So, let's use a specific  example. So, here we have an activity  classifier network which takes  motion sensory data as input. For example, reading some  sensors like an accelerometer or  a gyroscope. And then the network uses this  data to identify a physical  activity performed by the user. So, for example, we want to know  if a user is cycling, skiing, or  walking. As you can see, this network is  set up in an interesting way. So, it contains a series of CNN  primitives, followed by LSTM  primitive, followed by more CNN  primitives. So, why is it set up this way?  Let's take a look. So, even though our input is  sensor data, it's represented by  a batch of 1D images with six  feature channels. So, one feature channel for  access in the accelerometer and  gyroscope readings. And each 1D image has 2,000  pixels. And you can think of them as  samples in time because the  activity we're trying to  identify, occurs over time. And then we pass these images  through a 1D convolution  primitive which compresses these  2,000 samples, to just 20  samples. But it expends a number of  feature channels, because -- so,  we're not losing any features in  the data. And then, this new  representation of the data, is  passed to LSTM primitive as a  sequence of lengths 20.

但是首先，让我们来回顾一下递归神经网络是什么？卷积神经网络的缺点之一是它们无法记住先前发生的任何事情。它们可以获取一个输入，例如图像，并生成一个输出，例如图像中所描绘的一组概率。另一方面，RNNs有记忆。他们擅长操作输入和输出序列。例如，它们可以采用一组概率，所以在图像中描绘的是什么，它是CNN的输出，并生成输出序列，该输出序列是组成该图像的标题的词序列。它们还可以接受一系列输入，例如组成句子的单词序列，并产生一系列输出，这些输出是相同的句子，但被翻译成不同的语言。例如，定量或完成。支持，RNNs的许多不同的方差。最常用的是短时记忆RNN，简称LSTM。在去年的WWDC会议上，我们广泛地讨论了LSTM内部的门，并介绍了LSTM的推理示例。因此，请参阅该会话获得更多关于LSTM推断的信息。今年，我们为RNS的所有这些变体增加了对培训的支持。在本次会议中，我将讨论LSTMs的训练。所以，让我们使用一个具体的例子。因此，这里有一个以运动感觉数据作为输入的活动分类器网络。例如，读取一些传感器，如加速度计或陀螺仪。然后网络使用该数据来识别用户执行的物理活动。例如，我们想知道用户是骑自行车、滑雪还是步行。正如你所看到的，这个网络是建立在一个有趣的方式。因此，它包含了一系列美国有线电视新闻网原语，其次是LSTM原语，其次是更多的美国有线电视新闻网原语。那么，为什么会这样设置呢？让我们看一看。因此，即使我们的输入是传感器数据，它是由一批具有六个特征通道的1D图像表示的。因此，加速度计和陀螺仪读数中的一个特征通道用于访问。每个一维图像都有2000个像素。你可以认为它们是时间的样本，因为我们试图识别的活动是随着时间的推移而发生的。然后，我们将这些图像通过1D卷积基元，压缩这2000个样本，仅20个样本。但是它消耗了大量的特征通道，因为我们不会丢失数据中的任何特征。然后，这个新的数据表示，作为长度为20的序列传递给LSTM原语。

 And we ran LSTM for 20  iterations. So, our LSTM is operating on a  sequence of lengths 20 instead  of 2,000, so it's operating on a  higher-level feature  representation of the data. And then we have additional CNN  primitives that we find  high-level features in the data. And the last primitive in this  network is the SoftMax primitive  which generates probabilities  for the different activity  classes, which is the output of  the network. And now, let's take a look at  how to train this network. So, we again need a loss  primitive, which takes the  output of the network and the  labels as input. And then we need the second half  of the graph. So, in the second half of the  graph, we again have gradient  primitives for the corresponding  forward primitives, including  the LSTM primitive. And now, for training, we do the  forward pass through the  network, then we compute loss,  and we do the gradient pass to  compute gradients that will be  used to update weights. So, this is a very similar setup  that we have for a CNN training. And the last step is of course  to update the weights and as you  know, the LSTM also has weights,  so they need to be updated as  well. And now, let's take a look at  how to train this network in  MPS. But first, let's take a look at  how we can create LSTM layer for  training using our framework.

我们运行LSTM进行20次迭代。因此，我们的LSTM是以长度为20的序列而不是2000进行操作的，因此它以数据的更高级别的特征表示进行操作。然后我们有附加的美国有线电视新闻网原语，我们在数据中找到高级特征。这个网络中最后一个基元是SoftMax基元，它为不同的活动类生成概率，这是网络的输出。现在，让我们来看看如何训练这个网络。因此，我们再次需要一个损失原语，它以网络的输出和标签作为输入。然后我们需要图的后半部分。因此，在图的后半部分，我们再次为相应的正向基元提供了梯度基元，包括LSTM基元。现在，对于训练，我们先通过网络进行正向传递，然后计算损失，再通过梯度传递来计算用于更新权重的梯度。所以，这是一个非常相似的设置，我们有一个美国有线电视新闻网的培训。最后一步当然是更新权重，正如你所知道的，LSTM也有权重，因此它们也需要更新。现在，让我们来看看如何在MPS中培训这个网络。但是首先，让我们来看看如何使用我们的框架来创建LSTM层来进行培训。

 So, first, you need to create  LSTM layer descriptor. And we initialize the descriptor  with initial training parameters  using data source providers. So, these initial training  parameters are, use smaller  random number or some checkpoint  values. The descriptor setup for  training, is exactly the same as  it is for inference. And we discussed the layer  descriptor setup in our last  year WWDC session in a lot more  detail. So, I want to refer you to the  session for more information on  LSTM layer descriptor setup. Once you have the descriptor,  the next step is to create LSTM  training layer with this  descriptor. MPS will populate training  weights using the data sources  specified in the descriptor. And we also need to have some  matrices to hold the computed  gradients. You will use the  createWeightGradientMatrices API  on the training layer to create  these matrices. And then, the training weights  will be used in a forward and  gradient passes and will be  passed to an optimizer along  with the computed gradients,  job, to date, weights. And now we need to prepare some  inputs and outputs for training  our LSTM.

所以，首先，你需要创建LSTM层描述符。我们使用数据源提供程序初始化描述符，并带有初始训练参数。因此，这些初始训练参数是使用较小的随机数或一些检查点值。用于训练的描述符设置与推理完全一样。我们更详细地讨论了去年WWDC会话中的层描述符设置。因此，我想向您介绍有关LSTM层描述符设置的更多信息。一旦你有了描述符，下一步就是用这个描述符创建LSTM训练层。MPS将使用描述符中指定的数据源填充训练权重。我们还需要一些矩阵来保持计算的梯度。您将在训练层使用CeaDeWeiTrimeMatrimeAPI创建这些矩阵。然后，训练权重将被用于正向和梯度传递，并将连同计算出的梯度、作业、迄今为止的权重一起传递给优化器。现在我们需要准备一些输入和输出来训练我们的LSTM。

 So, here's an example of how you  can create the matrices to hold  the input and output sequences  for both the forward and  gradient passes. You will need 20 matrices for  each one of those. And here is how you would  initialize these matrices with  data. And now, we are ready to train  our activity classifier network  in MPS. So, in this code example, I will  be highlighting only the LSTM  filter in the interest of time. So, in the forward pass, we ran  a sequence of 20 matrices  forward through the LSTM  training layer. And then in the backward pass,  we ran a sequence of 20 matrices  though the LSTM layer to compute  gradients. And now, you have the training  weights, and you have the  computed gradients, and you can  pass them to an optimizer to  update weights. So, there's just one more thing  I'd like to mention. [Inaudible] neural networks  operate on images and LSTMs  operate on matrices. And we'll provide convenience  kernels in the framework to make  it easy to convert between  images and matrices. So, in order to copy an image to  a matrix, you need to use the  MPI's Image Copy to Matrix  Kernel. So, this is how you can create  one, and this is how you can  encode one on a batch of images. Here, each row in a destination  matrix, will contain one source  image. And to copy from a matrix to an  image, you need to use the MPS  Matrix Copy to Image Kernel.

因此，这里有一个例子，说明如何创建矩阵来保存正向通道和梯度通道的输入和输出序列。每一个都需要20个矩阵。这里是如何用数据初始化这些矩阵。现在，我们准备在MPS中训练我们的活动分类器网络。因此，在这个代码示例中，为了兴趣，我只高亮LSTM过滤器。因此，在正向传递中，我们通过LSTM训练层向前运行20个矩阵的序列。然后在后向传递中，我们通过LSTM层来运行20个矩阵的序列来计算梯度。现在，你有了训练权重，还有计算出的梯度，你可以把它们传递给优化器来更新权重。所以，还有一件事我想提一下。神经网络对图像进行操作，LSTM在矩阵上操作。我们将在框架中提供便利内核，以便于在图像和矩阵之间转换。因此，为了将图像复制到矩阵，需要使用MPI的图像复制到矩阵内核。所以，这就是如何创建一个，这就是如何在一批图像上编码一个。这里，目标矩阵中的每一行将包含一个源图像。并且要从矩阵复制到图像，需要使用MPS矩阵复制到图像内核。

 This is how you can create one  and this is how you encode one  to the GPU. So, we just showed you how to  train CNNs and RNNs using MPS. We also showed you a demo of  Turi Create which is now powered  by MPS. And now it's time for one more  demo. We have been working with Google  to add support to the Metal  Performance Shaders Framework to  TensorFlow to accelerate machine  learning on macOS, and we would  love to show you a demo of that  in action. Specifically, we want to show  you a demo of training the  InceptionV3 Object  Classification Network, using  TensorFlow, powered by MPS. So, for this demo, I will again  be using a MacBook Pro with an  attached external GPU. So, I will be running TensorFlow  on this MacBook Pro, and I will  use an external GPU to train a  network using MPS. So, in this demo setup, I've  already imported TensorFlow and  preloaded the InceptionV3  Network and a training data set. So, now, let's train this  network for 30 iterations. So, you can see how fast this is  going. Again, the entire network, all  of the primitives, the  optimizer, and the weight update  step, everything is running on  the external GPU. And we're already done. And as you can see, the training  rate is approximately 100 images  per second. So, as was stated in the  platform State of the Union,  training the InceptionV3  Network, in TensorFlow powered  by MPS, is up to 20 times faster  than without MPS. So, this is it for the  TensorFlow demo. Thank you very much. And now, let's summarize this  session.

这就是如何创建一个，这就是如何将一个编码到GPU。所以，我们只是展示了如何使用MPS来训练CNNs和RNNs。我们还向您展示了Turi的演示，现在由MPS提供动力。现在是时候再演示一次了。我们一直在和Google合作，为TensorFlow的金属性能着色器框架增加支持，以加速MacOS上的机器学习，我们很乐意向您展示一个实际的演示。具体来说，我们想要向您展示一个使用TensorFlow在MPS支持下培训InceptionV3对象分类网络的演示。因此，对于这个演示，我将再次使用一个附加的外部GPU的MacBook Pro。所以，我将在MacBook Pro上运行TensorFlow，我将使用外部GPU来训练使用MPS的网络。因此，在这个演示安装中，我已经导入了TensorFlow并预加载了EnpEvTv3网络和一个训练数据集。现在，让我们训练这个网络进行30次迭代。所以，你可以看到这有多快。同样，整个网络、所有原语、优化器和权重更新步骤都在外部GPU上运行。我们已经完成了。正如你所看到的，训练速率大约是每秒100张图像。因此，正如在联合平台状态中所述，在MPS供电的TensorFlow中培训InceptionV3网络比没有MPS快20倍。所以，这是TunSoFraceDemo。非常感谢你。现在，让我们来总结一下这次会议。

 This year, we've added a FP16  accumulation for the convolution  and convolution transpose  primitives to improve the  performance of CNN inference. We've also added GPU accelerate  primitives for training neural  networks. These primitives are optimized  for both iOS and macOS. We've also added the neural  network graph API for training. It makes it very easy to train  neural networks on the GPU and  enables us to provide the best  performance across different  GPUs. For more information on this  session and links to related  resources, please go to our  developer website. We have the Metal for Machine  Learning Lab tomorrow at 9 a.m. So, we would love to talk to  you. So, please come talk to us. And thank you for coming and  have a great WWDC.

今年，我们为卷积和卷积转置原语添加了FP16累加以提高CNN推理的性能。我们还增加了用于训练神经网络的GPU加速基元。这些原语对IOS和MACOS都进行了优化。我们还添加了神经网络图形API来进行培训。它使得在GPU上训练神经网络变得非常容易，并使我们能够跨不同的GPU提供最好的性能。有关本次会议的更多信息和相关资源的链接，请访问我们的开发网站。我们明天早上9点有机器学习用的金属，所以我们很想和你谈谈。所以，请跟我们谈谈。谢谢你们的到来，并拥有一个伟大的WWDC。

